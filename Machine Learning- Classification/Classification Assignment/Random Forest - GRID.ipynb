{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa03b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3954c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"CKD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9899686b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>12300.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12400.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>9800.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9200.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp sg   al   su     rbc        pc         pcc  \\\n",
       "0     2.000000  76.459948  c  3.0  0.0  normal  abnormal  notpresent   \n",
       "1     3.000000  76.459948  c  2.0  0.0  normal    normal  notpresent   \n",
       "2     4.000000  76.459948  a  1.0  0.0  normal    normal  notpresent   \n",
       "3     5.000000  76.459948  d  1.0  0.0  normal    normal  notpresent   \n",
       "4     5.000000  50.000000  c  0.0  0.0  normal    normal  notpresent   \n",
       "..         ...        ... ..  ...  ...     ...       ...         ...   \n",
       "394  51.492308  70.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "395  51.492308  70.000000  c  0.0  2.0  normal    normal  notpresent   \n",
       "396  51.492308  70.000000  c  3.0  0.0  normal    normal  notpresent   \n",
       "397  51.492308  90.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "398  51.492308  80.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "\n",
       "             ba         bgr  ...        pcv            wc        rc  htn   dm  \\\n",
       "0    notpresent  148.112676  ...  38.868902   8408.191126  4.705597   no   no   \n",
       "1    notpresent  148.112676  ...  34.000000  12300.000000  4.705597   no   no   \n",
       "2    notpresent   99.000000  ...  34.000000   8408.191126  4.705597   no   no   \n",
       "3    notpresent  148.112676  ...  38.868902   8408.191126  4.705597   no   no   \n",
       "4    notpresent  148.112676  ...  36.000000  12400.000000  4.705597   no   no   \n",
       "..          ...         ...  ...        ...           ...       ...  ...  ...   \n",
       "394  notpresent  219.000000  ...  37.000000   9800.000000  4.400000   no   no   \n",
       "395  notpresent  220.000000  ...  27.000000   8408.191126  4.705597  yes  yes   \n",
       "396  notpresent  110.000000  ...  26.000000   9200.000000  3.400000  yes  yes   \n",
       "397  notpresent  207.000000  ...  38.868902   8408.191126  4.705597  yes  yes   \n",
       "398  notpresent  100.000000  ...  53.000000   8500.000000  4.900000   no   no   \n",
       "\n",
       "     cad  appet    pe  ane classification  \n",
       "0     no    yes   yes   no            yes  \n",
       "1     no    yes  poor   no            yes  \n",
       "2     no    yes  poor   no            yes  \n",
       "3     no    yes  poor  yes            yes  \n",
       "4     no    yes  poor   no            yes  \n",
       "..   ...    ...   ...  ...            ...  \n",
       "394   no    yes  poor   no            yes  \n",
       "395   no    yes  poor  yes            yes  \n",
       "396   no   poor  poor   no            yes  \n",
       "397   no    yes  poor  yes            yes  \n",
       "398   no    yes  poor   no             no  \n",
       "\n",
       "[399 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9eff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e7ff6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hrmo</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_normal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_yes</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_yes</th>\n",
       "      <th>classification_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>57.482105</td>\n",
       "      <td>3.077356</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>12.518156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp   al   su         bgr          bu        sc  \\\n",
       "0     2.000000  76.459948  3.0  0.0  148.112676   57.482105  3.077356   \n",
       "1     3.000000  76.459948  2.0  0.0  148.112676   22.000000  0.700000   \n",
       "2     4.000000  76.459948  1.0  0.0   99.000000   23.000000  0.600000   \n",
       "3     5.000000  76.459948  1.0  0.0  148.112676   16.000000  0.700000   \n",
       "4     5.000000  50.000000  0.0  0.0  148.112676   25.000000  0.600000   \n",
       "..         ...        ...  ...  ...         ...         ...       ...   \n",
       "394  51.492308  70.000000  0.0  0.0  219.000000   36.000000  1.300000   \n",
       "395  51.492308  70.000000  0.0  2.0  220.000000   68.000000  2.800000   \n",
       "396  51.492308  70.000000  3.0  0.0  110.000000  115.000000  6.000000   \n",
       "397  51.492308  90.000000  0.0  0.0  207.000000   80.000000  6.800000   \n",
       "398  51.492308  80.000000  0.0  0.0  100.000000   49.000000  1.000000   \n",
       "\n",
       "            sod       pot       hrmo  ...  pc_normal  pcc_present  ba_present  \\\n",
       "0    137.528754  4.627244  12.518156  ...          0            0           0   \n",
       "1    137.528754  4.627244  10.700000  ...          1            0           0   \n",
       "2    138.000000  4.400000  12.000000  ...          1            0           0   \n",
       "3    138.000000  3.200000   8.100000  ...          1            0           0   \n",
       "4    137.528754  4.627244  11.800000  ...          1            0           0   \n",
       "..          ...       ...        ...  ...        ...          ...         ...   \n",
       "394  139.000000  3.700000  12.500000  ...          1            0           0   \n",
       "395  137.528754  4.627244   8.700000  ...          1            0           0   \n",
       "396  134.000000  2.700000   9.100000  ...          1            0           0   \n",
       "397  142.000000  5.500000   8.500000  ...          1            0           0   \n",
       "398  140.000000  5.000000  16.300000  ...          1            0           0   \n",
       "\n",
       "     htn_yes  dm_yes  cad_yes  appet_yes  pe_yes  ane_yes  classification_yes  \n",
       "0          0       0        0          1       1        0                   1  \n",
       "1          0       0        0          1       0        0                   1  \n",
       "2          0       0        0          1       0        0                   1  \n",
       "3          0       0        0          1       0        1                   1  \n",
       "4          0       0        0          1       0        0                   1  \n",
       "..       ...     ...      ...        ...     ...      ...                 ...  \n",
       "394        0       0        0          1       0        0                   1  \n",
       "395        1       1        0          1       0        1                   1  \n",
       "396        1       1        0          0       0        0                   1  \n",
       "397        1       1        0          1       0        1                   1  \n",
       "398        0       0        0          1       0        0                   0  \n",
       "\n",
       "[399 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045b146b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv',\n",
       "       'wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
       "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
       "       'appet_yes', 'pe_yes', 'ane_yes', 'classification_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "191c2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep=dataset[['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv',\n",
    "       'wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
    "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
    "       'appet_yes', 'pe_yes', 'ane_yes']]\n",
    "dep=dataset[['classification_yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f9e4796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification_yes\n",
       "1    249\n",
       "0    150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"classification_yes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88eb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(indep,dep,test_size=1/3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d19e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train= sc.fit_transform(X_train)\n",
    "X_test= sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b0fa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "135 fits failed out of a total of 405.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "99 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of RandomForestClassifier must be a str among {'balanced_subsample', 'balanced'}, an instance of 'dict', an instance of 'list' or None. Got 'dict' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of RandomForestClassifier must be a str among {'balanced', 'balanced_subsample'}, an instance of 'dict', an instance of 'list' or None. Got 'dict' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.94774127 0.95475073 0.9581861  0.97360845 0.98480061 0.9734433\n",
      " 0.96972702 0.9696495  0.97712948 0.9474133  0.94689937 0.950535\n",
      " 0.966367   0.97731843 0.97712948 0.97745733 0.98104724 0.98480061\n",
      " 0.95485385 0.94325586 0.94675814 0.96608784 0.96975788 0.98111443\n",
      " 0.9660574  0.98104724 0.97712948        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.93676624 0.95080164 0.9395561  0.98123739 0.97011694 0.9810718\n",
      " 0.97715404 0.97741902 0.97377403 0.95095547 0.95451689 0.94688388\n",
      " 0.95857351 0.97370397 0.98480061 0.97731521 0.96997516 0.97715404\n",
      " 0.94696248 0.95059913 0.94689937 0.95521948 0.97719667 0.97346786\n",
      " 0.97730453 0.97719667 0.97712948]\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, &#x27;dict&#x27;, None],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, &#x27;dict&#x27;, None],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', 'dict', None],\n",
       "                         'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': [None, 'sqrt', 'log2'],\n",
       "                         'n_estimators': [10, 50, 100]},\n",
       "             scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid={'criterion':[\"gini\", \"entropy\", \"log_loss\"], 'class_weight': ['balanced', 'dict', None], 'max_features': [None,\"sqrt\", \"log2\"], 'n_estimators':[10,50,100]}\n",
    "grid= GridSearchCV(RandomForestClassifier(), param_grid, refit= True, verbose=3, n_jobs=-1, scoring= 'f1_weighted' )\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a3a7775",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffcba057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  0],\n",
       "       [ 0, 82]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5438959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf_report=classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bffd0601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       1.00      1.00      1.00        82\n",
      "\n",
      "    accuracy                           1.00       133\n",
      "   macro avg       1.00      1.00      1.00       133\n",
      "weighted avg       1.00      1.00      1.00       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99a71947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_score= roc_auc_score(y_test,grid.predict_proba(X_test)[:,1])\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4117b642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the best parameter is  {'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print ( \" the best parameter is \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd902e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.04488044, 0.17513232, 0.35544968, 0.04009161, 0.12885828,\n",
       "        0.27406831, 0.03869619, 0.13224907, 0.25850892, 0.04727325,\n",
       "        0.19348354, 0.34866457, 0.03331027, 0.13045049, 0.28583608,\n",
       "        0.03769355, 0.14281626, 0.30258718, 0.04747262, 0.1753273 ,\n",
       "        0.35086122, 0.03749967, 0.13843274, 0.27167277, 0.03211675,\n",
       "        0.13244057, 0.26409335, 0.00099702, 0.00060196, 0.00099602,\n",
       "        0.00099401, 0.00079861, 0.00079756, 0.0007987 , 0.00099907,\n",
       "        0.00059896, 0.00079875, 0.0009973 , 0.0007936 , 0.00039916,\n",
       "        0.00079622, 0.00099616, 0.00099907, 0.00059443, 0.00139713,\n",
       "        0.00119934, 0.00059795, 0.00059886, 0.00039811, 0.00059819,\n",
       "        0.00099831, 0.00079374, 0.00079398, 0.00099449, 0.05245719,\n",
       "        0.18929062, 0.33330693, 0.03470602, 0.1402245 , 0.25411954,\n",
       "        0.03810134, 0.13024974, 0.26249719, 0.04468241, 0.18250813,\n",
       "        0.34986868, 0.03350501, 0.1360342 , 0.27047772, 0.03550811,\n",
       "        0.13583589, 0.25910535, 0.0420867 , 0.18271008, 0.33749542,\n",
       "        0.033708  , 0.136834  , 0.26608815, 0.03351135, 0.13543324,\n",
       "        0.2585063 ]),\n",
       " 'std_fit_time': array([6.52524623e-03, 1.08984376e-02, 1.60021503e-02, 9.21518084e-03,\n",
       "        9.91696001e-03, 2.49710857e-02, 1.69533250e-02, 1.57995583e-02,\n",
       "        1.01989333e-02, 8.23934496e-03, 5.53234469e-03, 1.07303482e-02,\n",
       "        4.21214009e-03, 8.13673348e-03, 2.75491241e-02, 6.95257844e-03,\n",
       "        1.63691261e-02, 2.86212558e-02, 9.86577251e-03, 1.11695183e-02,\n",
       "        1.61975633e-02, 7.26296943e-03, 8.16372319e-03, 2.33176378e-02,\n",
       "        3.75294354e-03, 4.57208207e-03, 1.47855045e-02, 8.44957597e-07,\n",
       "        4.91518909e-04, 6.30678399e-04, 6.83625521e-06, 3.99305572e-04,\n",
       "        3.98779528e-04, 3.99351590e-04, 1.17383324e-06, 4.89045487e-04,\n",
       "        3.99375229e-04, 6.30977281e-04, 3.96883331e-04, 4.88869780e-04,\n",
       "        3.98119610e-04, 2.97173242e-06, 7.09286257e-06, 4.85361659e-04,\n",
       "        7.98106555e-04, 4.03118951e-04, 4.88227603e-04, 4.88967186e-04,\n",
       "        4.87584972e-04, 4.88422185e-04, 1.12234137e-06, 3.96963810e-04,\n",
       "        3.97086481e-04, 1.50535610e-05, 1.65767811e-02, 1.02196544e-02,\n",
       "        1.29861881e-02, 6.35256730e-03, 1.18610947e-02, 5.72769398e-03,\n",
       "        6.82961539e-03, 1.25614985e-02, 1.50320229e-02, 6.47977601e-03,\n",
       "        1.16734023e-02, 1.89325975e-02, 3.48544824e-03, 7.53572984e-03,\n",
       "        1.30113015e-02, 4.25707935e-03, 3.04939915e-03, 6.03119416e-03,\n",
       "        7.09168177e-03, 1.07486992e-02, 6.38840557e-03, 4.65127296e-03,\n",
       "        9.96182005e-03, 1.74278429e-02, 3.07006182e-03, 1.26258756e-02,\n",
       "        7.03394129e-03]),\n",
       " 'mean_score_time': array([0.01296568, 0.02473421, 0.02633023, 0.01176896, 0.0191473 ,\n",
       "        0.02792277, 0.01237006, 0.02054238, 0.03191681, 0.01476116,\n",
       "        0.01994848, 0.02473397, 0.01157107, 0.01994729, 0.03591061,\n",
       "        0.0207437 , 0.02214088, 0.02812867, 0.01376667, 0.01875014,\n",
       "        0.03191557, 0.01356387, 0.02133961, 0.02712812, 0.01336126,\n",
       "        0.01875029, 0.02992029, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01416683,\n",
       "        0.02054701, 0.03011737, 0.01615558, 0.018753  , 0.02593613,\n",
       "        0.01256332, 0.02254033, 0.02593079, 0.01335964, 0.01954398,\n",
       "        0.03111715, 0.01356626, 0.0183486 , 0.02852387, 0.01336484,\n",
       "        0.0201458 , 0.02513499, 0.01536245, 0.02174225, 0.02872367,\n",
       "        0.01336455, 0.0203455 , 0.02732763, 0.01356473, 0.02074628,\n",
       "        0.02513366]),\n",
       " 'std_score_time': array([0.00109271, 0.00747519, 0.00354581, 0.00116338, 0.00192918,\n",
       "        0.00508623, 0.00135197, 0.0037114 , 0.00694072, 0.00469461,\n",
       "        0.00552894, 0.00171526, 0.0013527 , 0.00282032, 0.01007689,\n",
       "        0.00739369, 0.00513936, 0.00438387, 0.00270247, 0.00116376,\n",
       "        0.00661537, 0.00256981, 0.00449026, 0.00230946, 0.00174034,\n",
       "        0.00171538, 0.00588286, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00203821,\n",
       "        0.00185035, 0.00494586, 0.00558616, 0.00231187, 0.00166489,\n",
       "        0.00185049, 0.00510901, 0.00125891, 0.00184404, 0.00285647,\n",
       "        0.00550596, 0.00102054, 0.00119539, 0.00223805, 0.00185437,\n",
       "        0.00171547, 0.00146417, 0.00271642, 0.0061611 , 0.0044779 ,\n",
       "        0.00119746, 0.00286299, 0.00886587, 0.00135089, 0.00612866,\n",
       "        0.00116298]),\n",
       " 'param_class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'dict', 'dict',\n",
       "                    'dict', 'dict', 'dict', 'dict', 'dict', 'dict', 'dict',\n",
       "                    'dict', 'dict', 'dict', 'dict', 'dict', 'dict', 'dict',\n",
       "                    'dict', 'dict', 'dict', 'dict', 'dict', 'dict', 'dict',\n",
       "                    'dict', 'dict', 'dict', 'dict', None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[None, None, None, 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', None, None, None, 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', None, None, None,\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', None,\n",
       "                    None, None, 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', None, None, None, 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'log2', None, None, None, 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', None, None,\n",
       "                    None, 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    None, None, None, 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', None, None, None, 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10,\n",
       "                    50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 100},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 10},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 50},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 100}],\n",
       " 'split0_test_score': array([0.92656726, 0.94470736, 0.98137826, 1.        , 1.        ,\n",
       "        0.98156912, 1.        , 0.98156912, 1.        , 0.92656726,\n",
       "        0.96328363, 0.96296296, 0.96328363, 1.        , 1.        ,\n",
       "        0.96328363, 1.        , 1.        , 0.96328363, 0.92656726,\n",
       "        0.96328363, 0.98156912, 0.98156912, 0.98156912, 0.96328363,\n",
       "        1.        , 1.        ,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan, 0.87242798,\n",
       "        0.94470736, 0.92656726, 0.98156912, 0.96328363, 1.        ,\n",
       "        1.        , 0.98156912, 0.98156912, 0.96296296, 0.96328363,\n",
       "        0.94470736, 0.98156912, 0.96328363, 1.        , 1.        ,\n",
       "        0.96328363, 1.        , 0.94510038, 0.96328363, 0.96328363,\n",
       "        0.90887713, 0.98156912, 0.98156912, 1.        , 0.98156912,\n",
       "        1.        ]),\n",
       " 'split1_test_score': array([0.98101383, 0.9421662 , 0.9421662 , 0.96175502, 0.96175502,\n",
       "        0.9421662 , 0.96175502, 0.9421662 , 0.9421662 , 0.9421662 ,\n",
       "        0.9421662 , 0.9421662 , 0.96226415, 0.96175502, 0.9421662 ,\n",
       "        0.96175502, 0.96175502, 0.96175502, 0.9421662 , 0.9421662 ,\n",
       "        0.9421662 , 0.98101383, 0.9421662 , 0.96175502, 0.9421662 ,\n",
       "        0.96175502, 0.9421662 ,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan, 0.96175502,\n",
       "        0.96175502, 0.9421662 , 0.98101383, 0.98101383, 0.96175502,\n",
       "        0.9421662 , 0.98101383, 0.98101383, 0.9421662 , 0.96175502,\n",
       "        0.9421662 , 0.92351003, 0.96175502, 0.96175502, 0.96175502,\n",
       "        0.96175502, 0.9421662 , 0.9421662 , 0.9421662 , 0.9421662 ,\n",
       "        0.9421662 , 0.9421662 , 0.9421662 , 0.94304148, 0.9421662 ,\n",
       "        0.9421662 ]),\n",
       " 'split2_test_score': array([0.90703509, 0.94402307, 0.94402307, 0.94402307, 0.98121703,\n",
       "        0.98121703, 0.94402307, 0.98121703, 0.98121703, 0.94402307,\n",
       "        0.92552426, 0.94402307, 0.94402307, 0.962573  , 0.98121703,\n",
       "        0.98121703, 0.98121703, 0.98121703, 0.92552426, 0.94402307,\n",
       "        0.94402307, 0.92552426, 0.94402307, 0.98121703, 0.962573  ,\n",
       "        0.98121703, 0.98121703,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan, 0.92552426,\n",
       "        0.94402307, 0.92552426, 0.962573  , 0.94402307, 0.962573  ,\n",
       "        0.962573  , 0.98121703, 0.94402307, 0.92552426, 0.94402307,\n",
       "        0.94402307, 0.92552426, 0.98121703, 0.98121703, 0.962573  ,\n",
       "        0.962573  , 0.962573  , 0.94402307, 0.94402307, 0.92552426,\n",
       "        0.94402307, 0.98121703, 0.962573  , 0.98121703, 0.98121703,\n",
       "        0.98121703]),\n",
       " 'split3_test_score': array([0.96182604, 0.96182604, 0.942332  , 0.96226415, 0.98103098,\n",
       "        0.96226415, 0.98103098, 0.96226415, 0.96226415, 0.94309295,\n",
       "        0.92249176, 0.92249176, 0.96226415, 0.96226415, 0.96226415,\n",
       "        0.98103098, 0.96226415, 0.98103098, 0.96226415, 0.92249176,\n",
       "        0.92249176, 0.942332  , 0.98103098, 0.98103098, 0.96226415,\n",
       "        0.96226415, 0.96226415,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan, 0.94309295,\n",
       "        0.92249176, 0.92249176, 0.98103098, 0.96226415, 0.98103098,\n",
       "        0.98103098, 0.96226415, 0.96226415, 0.94309295, 0.92249176,\n",
       "        0.92249176, 0.96226415, 0.96226415, 0.98103098, 0.98103098,\n",
       "        0.96226415, 0.98103098, 0.92249176, 0.92249176, 0.92249176,\n",
       "        0.98103098, 0.98103098, 0.98103098, 0.96226415, 0.98103098,\n",
       "        0.96226415]),\n",
       " 'split4_test_score': array([0.96226415, 0.98103098, 0.98103098, 1.        , 1.        ,\n",
       "        1.        , 0.96182604, 0.98103098, 1.        , 0.98121703,\n",
       "        0.98103098, 0.98103098, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.98103098, 0.98103098,\n",
       "        0.96182604, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        ,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan, 0.98103098,\n",
       "        0.98103098, 0.98103098, 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.98103098, 1.        , 0.98103098, 0.98103098,\n",
       "        0.98103098, 1.        , 1.        , 1.        , 0.98121703,\n",
       "        1.        , 1.        , 0.98103098, 0.98103098, 0.98103098,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " 'mean_test_score': array([0.94774127, 0.95475073, 0.9581861 , 0.97360845, 0.98480061,\n",
       "        0.9734433 , 0.96972702, 0.9696495 , 0.97712948, 0.9474133 ,\n",
       "        0.94689937, 0.950535  , 0.966367  , 0.97731843, 0.97712948,\n",
       "        0.97745733, 0.98104724, 0.98480061, 0.95485385, 0.94325586,\n",
       "        0.94675814, 0.96608784, 0.96975788, 0.98111443, 0.9660574 ,\n",
       "        0.98104724, 0.97712948,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan, 0.93676624,\n",
       "        0.95080164, 0.9395561 , 0.98123739, 0.97011694, 0.9810718 ,\n",
       "        0.97715404, 0.97741902, 0.97377403, 0.95095547, 0.95451689,\n",
       "        0.94688388, 0.95857351, 0.97370397, 0.98480061, 0.97731521,\n",
       "        0.96997516, 0.97715404, 0.94696248, 0.95059913, 0.94689937,\n",
       "        0.95521948, 0.97719667, 0.97346786, 0.97730453, 0.97719667,\n",
       "        0.97712948]),\n",
       " 'std_test_score': array([0.02691353, 0.01493341, 0.01880609, 0.02252785, 0.01428422,\n",
       "        0.01967205, 0.01913585, 0.01559037, 0.02238856, 0.01808281,\n",
       "        0.02239839, 0.01991645, 0.01829538, 0.01852126, 0.02238856,\n",
       "        0.01401809, 0.01699081, 0.01428422, 0.01914376, 0.02068039,\n",
       "        0.0149503 , 0.02764863, 0.02282435, 0.01209691, 0.01874627,\n",
       "        0.01699081, 0.02238856,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan, 0.03712042,\n",
       "        0.01958738, 0.02183471, 0.01183721, 0.01897888, 0.01692276,\n",
       "        0.02234127, 0.00758007, 0.01907132, 0.01915481, 0.01983922,\n",
       "        0.01895351, 0.03026639, 0.01503435, 0.01428422, 0.01416392,\n",
       "        0.01502059, 0.02234127, 0.01894514, 0.01995684, 0.02239839,\n",
       "        0.03198403, 0.01895842, 0.01962283, 0.02211626, 0.01895842,\n",
       "        0.02238856]),\n",
       " 'rank_test_score': array([45, 39, 36, 24,  1, 26, 30, 31, 18, 46, 48, 44, 32, 11, 18,  9,  7,\n",
       "         1, 38, 52, 51, 33, 29,  5, 34,  7, 18, 55, 55, 55, 55, 55, 55, 55,\n",
       "        55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,\n",
       "        55, 55, 55, 54, 42, 53,  4, 27,  6, 16, 10, 22, 41, 40, 50, 35, 23,\n",
       "         1, 12, 28, 16, 47, 43, 48, 37, 14, 25, 13, 14, 18])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76175f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "re=grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "730d34e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044880</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>0.012966</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.926567</td>\n",
       "      <td>0.981014</td>\n",
       "      <td>0.907035</td>\n",
       "      <td>0.961826</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.947741</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.175132</td>\n",
       "      <td>0.010898</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.944707</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>0.961826</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.954751</td>\n",
       "      <td>0.014933</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.355450</td>\n",
       "      <td>0.016002</td>\n",
       "      <td>0.026330</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.981378</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>0.942332</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.958186</td>\n",
       "      <td>0.018806</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040092</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973608</td>\n",
       "      <td>0.022528</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.128858</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>0.019147</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984801</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.136834</td>\n",
       "      <td>0.009962</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977197</td>\n",
       "      <td>0.018958</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.266088</td>\n",
       "      <td>0.017428</td>\n",
       "      <td>0.027328</td>\n",
       "      <td>0.008866</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973468</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.033511</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943041</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977305</td>\n",
       "      <td>0.022116</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.135433</td>\n",
       "      <td>0.012626</td>\n",
       "      <td>0.020746</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977197</td>\n",
       "      <td>0.018958</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.258506</td>\n",
       "      <td>0.007034</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977129</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.044880      0.006525         0.012966        0.001093   \n",
       "1        0.175132      0.010898         0.024734        0.007475   \n",
       "2        0.355450      0.016002         0.026330        0.003546   \n",
       "3        0.040092      0.009215         0.011769        0.001163   \n",
       "4        0.128858      0.009917         0.019147        0.001929   \n",
       "..            ...           ...              ...             ...   \n",
       "76       0.136834      0.009962         0.020345        0.002863   \n",
       "77       0.266088      0.017428         0.027328        0.008866   \n",
       "78       0.033511      0.003070         0.013565        0.001351   \n",
       "79       0.135433      0.012626         0.020746        0.006129   \n",
       "80       0.258506      0.007034         0.025134        0.001163   \n",
       "\n",
       "   param_class_weight param_criterion param_max_features param_n_estimators  \\\n",
       "0            balanced            gini               None                 10   \n",
       "1            balanced            gini               None                 50   \n",
       "2            balanced            gini               None                100   \n",
       "3            balanced            gini               sqrt                 10   \n",
       "4            balanced            gini               sqrt                 50   \n",
       "..                ...             ...                ...                ...   \n",
       "76               None        log_loss               sqrt                 50   \n",
       "77               None        log_loss               sqrt                100   \n",
       "78               None        log_loss               log2                 10   \n",
       "79               None        log_loss               log2                 50   \n",
       "80               None        log_loss               log2                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'class_weight': 'balanced', 'criterion': 'gin...           0.926567   \n",
       "1   {'class_weight': 'balanced', 'criterion': 'gin...           0.944707   \n",
       "2   {'class_weight': 'balanced', 'criterion': 'gin...           0.981378   \n",
       "3   {'class_weight': 'balanced', 'criterion': 'gin...           1.000000   \n",
       "4   {'class_weight': 'balanced', 'criterion': 'gin...           1.000000   \n",
       "..                                                ...                ...   \n",
       "76  {'class_weight': None, 'criterion': 'log_loss'...           0.981569   \n",
       "77  {'class_weight': None, 'criterion': 'log_loss'...           0.981569   \n",
       "78  {'class_weight': None, 'criterion': 'log_loss'...           1.000000   \n",
       "79  {'class_weight': None, 'criterion': 'log_loss'...           0.981569   \n",
       "80  {'class_weight': None, 'criterion': 'log_loss'...           1.000000   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.981014           0.907035           0.961826   \n",
       "1            0.942166           0.944023           0.961826   \n",
       "2            0.942166           0.944023           0.942332   \n",
       "3            0.961755           0.944023           0.962264   \n",
       "4            0.961755           0.981217           0.981031   \n",
       "..                ...                ...                ...   \n",
       "76           0.942166           0.981217           0.981031   \n",
       "77           0.942166           0.962573           0.981031   \n",
       "78           0.943041           0.981217           0.962264   \n",
       "79           0.942166           0.981217           0.981031   \n",
       "80           0.942166           0.981217           0.962264   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.962264         0.947741        0.026914               45  \n",
       "1            0.981031         0.954751        0.014933               39  \n",
       "2            0.981031         0.958186        0.018806               36  \n",
       "3            1.000000         0.973608        0.022528               24  \n",
       "4            1.000000         0.984801        0.014284                1  \n",
       "..                ...              ...             ...              ...  \n",
       "76           1.000000         0.977197        0.018958               14  \n",
       "77           1.000000         0.973468        0.019623               25  \n",
       "78           1.000000         0.977305        0.022116               13  \n",
       "79           1.000000         0.977197        0.018958               14  \n",
       "80           1.000000         0.977129        0.022389               18  \n",
       "\n",
       "[81 rows x 17 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table= pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce041c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9848006070227224"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b9547f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.25720128e-01,  1.18386687e+00,  7.43679000e+00,\n",
       "         4.68015545e+00, -3.88079651e-01, -2.48869935e-03,\n",
       "        -2.86774811e-01,  5.15346177e-01, -2.58764074e-01,\n",
       "        -1.75196181e-01,  2.70805503e+00, -1.31927538e-01,\n",
       "         3.97885360e-01, -4.92940822e-01, -5.45491499e-01,\n",
       "        -4.51242628e-01, -1.38409133e-01,  3.89249472e-01,\n",
       "         5.10552159e-01, -3.42997170e-01,  4.24264069e+00,\n",
       "         1.35269628e+00,  1.35269628e+00, -2.92770022e-01,\n",
       "        -1.93649167e+00, -5.22232968e-01, -4.45194562e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_input= sc.transform([[50,92,10,5,120,60,1.5,143,4,12,61,8000,5,0,0,0,0,1,1,0,1,1,1,0,0,0,0]])\n",
    "pre_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1904615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result= grid.predict(pre_input)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61230fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
