{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa03b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3954c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"CKD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9899686b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>12300.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12400.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>9800.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9200.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp sg   al   su     rbc        pc         pcc  \\\n",
       "0     2.000000  76.459948  c  3.0  0.0  normal  abnormal  notpresent   \n",
       "1     3.000000  76.459948  c  2.0  0.0  normal    normal  notpresent   \n",
       "2     4.000000  76.459948  a  1.0  0.0  normal    normal  notpresent   \n",
       "3     5.000000  76.459948  d  1.0  0.0  normal    normal  notpresent   \n",
       "4     5.000000  50.000000  c  0.0  0.0  normal    normal  notpresent   \n",
       "..         ...        ... ..  ...  ...     ...       ...         ...   \n",
       "394  51.492308  70.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "395  51.492308  70.000000  c  0.0  2.0  normal    normal  notpresent   \n",
       "396  51.492308  70.000000  c  3.0  0.0  normal    normal  notpresent   \n",
       "397  51.492308  90.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "398  51.492308  80.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "\n",
       "             ba         bgr  ...        pcv            wc        rc  htn   dm  \\\n",
       "0    notpresent  148.112676  ...  38.868902   8408.191126  4.705597   no   no   \n",
       "1    notpresent  148.112676  ...  34.000000  12300.000000  4.705597   no   no   \n",
       "2    notpresent   99.000000  ...  34.000000   8408.191126  4.705597   no   no   \n",
       "3    notpresent  148.112676  ...  38.868902   8408.191126  4.705597   no   no   \n",
       "4    notpresent  148.112676  ...  36.000000  12400.000000  4.705597   no   no   \n",
       "..          ...         ...  ...        ...           ...       ...  ...  ...   \n",
       "394  notpresent  219.000000  ...  37.000000   9800.000000  4.400000   no   no   \n",
       "395  notpresent  220.000000  ...  27.000000   8408.191126  4.705597  yes  yes   \n",
       "396  notpresent  110.000000  ...  26.000000   9200.000000  3.400000  yes  yes   \n",
       "397  notpresent  207.000000  ...  38.868902   8408.191126  4.705597  yes  yes   \n",
       "398  notpresent  100.000000  ...  53.000000   8500.000000  4.900000   no   no   \n",
       "\n",
       "     cad  appet    pe  ane classification  \n",
       "0     no    yes   yes   no            yes  \n",
       "1     no    yes  poor   no            yes  \n",
       "2     no    yes  poor   no            yes  \n",
       "3     no    yes  poor  yes            yes  \n",
       "4     no    yes  poor   no            yes  \n",
       "..   ...    ...   ...  ...            ...  \n",
       "394   no    yes  poor   no            yes  \n",
       "395   no    yes  poor  yes            yes  \n",
       "396   no   poor  poor   no            yes  \n",
       "397   no    yes  poor  yes            yes  \n",
       "398   no    yes  poor   no             no  \n",
       "\n",
       "[399 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9eff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e7ff6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hrmo</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_normal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_yes</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_yes</th>\n",
       "      <th>classification_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>57.482105</td>\n",
       "      <td>3.077356</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>12.518156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp   al   su         bgr          bu        sc  \\\n",
       "0     2.000000  76.459948  3.0  0.0  148.112676   57.482105  3.077356   \n",
       "1     3.000000  76.459948  2.0  0.0  148.112676   22.000000  0.700000   \n",
       "2     4.000000  76.459948  1.0  0.0   99.000000   23.000000  0.600000   \n",
       "3     5.000000  76.459948  1.0  0.0  148.112676   16.000000  0.700000   \n",
       "4     5.000000  50.000000  0.0  0.0  148.112676   25.000000  0.600000   \n",
       "..         ...        ...  ...  ...         ...         ...       ...   \n",
       "394  51.492308  70.000000  0.0  0.0  219.000000   36.000000  1.300000   \n",
       "395  51.492308  70.000000  0.0  2.0  220.000000   68.000000  2.800000   \n",
       "396  51.492308  70.000000  3.0  0.0  110.000000  115.000000  6.000000   \n",
       "397  51.492308  90.000000  0.0  0.0  207.000000   80.000000  6.800000   \n",
       "398  51.492308  80.000000  0.0  0.0  100.000000   49.000000  1.000000   \n",
       "\n",
       "            sod       pot       hrmo  ...  pc_normal  pcc_present  ba_present  \\\n",
       "0    137.528754  4.627244  12.518156  ...          0            0           0   \n",
       "1    137.528754  4.627244  10.700000  ...          1            0           0   \n",
       "2    138.000000  4.400000  12.000000  ...          1            0           0   \n",
       "3    138.000000  3.200000   8.100000  ...          1            0           0   \n",
       "4    137.528754  4.627244  11.800000  ...          1            0           0   \n",
       "..          ...       ...        ...  ...        ...          ...         ...   \n",
       "394  139.000000  3.700000  12.500000  ...          1            0           0   \n",
       "395  137.528754  4.627244   8.700000  ...          1            0           0   \n",
       "396  134.000000  2.700000   9.100000  ...          1            0           0   \n",
       "397  142.000000  5.500000   8.500000  ...          1            0           0   \n",
       "398  140.000000  5.000000  16.300000  ...          1            0           0   \n",
       "\n",
       "     htn_yes  dm_yes  cad_yes  appet_yes  pe_yes  ane_yes  classification_yes  \n",
       "0          0       0        0          1       1        0                   1  \n",
       "1          0       0        0          1       0        0                   1  \n",
       "2          0       0        0          1       0        0                   1  \n",
       "3          0       0        0          1       0        1                   1  \n",
       "4          0       0        0          1       0        0                   1  \n",
       "..       ...     ...      ...        ...     ...      ...                 ...  \n",
       "394        0       0        0          1       0        0                   1  \n",
       "395        1       1        0          1       0        1                   1  \n",
       "396        1       1        0          0       0        0                   1  \n",
       "397        1       1        0          1       0        1                   1  \n",
       "398        0       0        0          1       0        0                   0  \n",
       "\n",
       "[399 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8949d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv',\n",
       "       'wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
       "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
       "       'appet_yes', 'pe_yes', 'ane_yes', 'classification_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "191c2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep=dataset[['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv',\n",
    "       'wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
    "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
    "       'appet_yes', 'pe_yes', 'ane_yes']]\n",
    "dep=dataset[['classification_yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f9e4796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification_yes\n",
       "1    249\n",
       "0    150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"classification_yes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88eb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(indep,dep,test_size=1/3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d19e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train= sc.fit_transform(X_train)\n",
    "X_test= sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b0fa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "90 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of DecisionTreeClassifier must be an instance of 'dict', an instance of 'list', a str among {'balanced'} or None. Got 'dict' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.95836522 0.9550477  0.96242799 0.98496619 0.94718045 0.96977414\n",
      " 0.94691201 0.98125347 0.95439858 0.95862597 0.94376121 0.95530263\n",
      " 0.94298424 0.96643819 0.9505725  0.96632694 0.94703991 0.96234858\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.9507906  0.97346543 0.94687407 0.97370074 0.95874441 0.96222496\n",
      " 0.93234082 0.96611547 0.94339073 0.97733852 0.95869669 0.95851434\n",
      " 0.93205461 0.98124796 0.95812866 0.97747537 0.9624762  0.94390078]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, &#x27;dict&#x27;, None],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, &#x27;dict&#x27;, None],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', 'dict', None],\n",
       "                         'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': [None, 'sqrt', 'log2'],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "param_grid={'criterion':[\"gini\", \"entropy\", \"log_loss\"], 'splitter': [\"best\", \"random\"], 'class_weight': ['balanced', 'dict', None], 'max_features': [None,\"sqrt\", \"log2\"]}\n",
    "grid= GridSearchCV(DecisionTreeClassifier(), param_grid, refit= True, verbose=3, n_jobs=-1, scoring= 'f1_weighted' )\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a3a7775",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffcba057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  2],\n",
       "       [ 3, 79]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5438959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf_report=classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bffd0601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        51\n",
      "           1       0.98      0.96      0.97        82\n",
      "\n",
      "    accuracy                           0.96       133\n",
      "   macro avg       0.96      0.96      0.96       133\n",
      "weighted avg       0.96      0.96      0.96       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99a71947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620994739359159"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_score= roc_auc_score(y_test,grid.predict_proba(X_test)[:,1])\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4117b642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the best parameter is  {'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'sqrt', 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "print ( \" the best parameter is \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd902e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00798182, 0.00558577, 0.0047893 , 0.00418873, 0.00418854,\n",
       "        0.00418935, 0.00598192, 0.00498466, 0.00418882, 0.0039969 ,\n",
       "        0.00379386, 0.00338688, 0.00658207, 0.00398922, 0.00398951,\n",
       "        0.00339084, 0.00458813, 0.0039897 , 0.00099783, 0.00099711,\n",
       "        0.00079823, 0.00099788, 0.00099316, 0.00099726, 0.00039864,\n",
       "        0.00079727, 0.00059776, 0.00079689, 0.00039849, 0.00039935,\n",
       "        0.00059829, 0.00078988, 0.00059876, 0.00079684, 0.00019956,\n",
       "        0.00059876, 0.00418115, 0.00299234, 0.00279093, 0.00299282,\n",
       "        0.00319166, 0.00398908, 0.00439138, 0.00398741, 0.00299268,\n",
       "        0.0033886 , 0.0037899 , 0.00378957, 0.00438499, 0.00398946,\n",
       "        0.00299191, 0.00339432, 0.00358558, 0.00299149]),\n",
       " 'std_fit_time': array([1.88871763e-03, 7.97677216e-04, 3.99941418e-04, 3.98899247e-04,\n",
       "        4.00066972e-04, 3.98946617e-04, 1.54535886e-03, 1.99638205e-03,\n",
       "        9.76786439e-04, 1.08581621e-03, 4.01046374e-04, 8.00120015e-04,\n",
       "        2.72057889e-03, 6.31429684e-04, 6.30072517e-04, 4.89161939e-04,\n",
       "        1.19709977e-03, 2.61174468e-07, 7.89305942e-07, 9.22159176e-07,\n",
       "        3.99113214e-04, 7.62939453e-07, 9.90238210e-06, 6.64157308e-07,\n",
       "        4.88227323e-04, 3.98636549e-04, 4.88073484e-04, 3.98447441e-04,\n",
       "        4.88054597e-04, 4.89103381e-04, 4.88500262e-04, 3.95036578e-04,\n",
       "        4.88889807e-04, 3.98543093e-04, 3.99112701e-04, 4.88889690e-04,\n",
       "        3.91916345e-04, 6.97552626e-07, 7.45974740e-04, 6.31128906e-04,\n",
       "        3.98183108e-04, 8.91696841e-04, 4.94742563e-04, 1.99647182e-03,\n",
       "        3.81469727e-07, 4.90717714e-04, 3.98636349e-04, 7.46582350e-04,\n",
       "        4.90769736e-04, 1.54501815e-03, 5.84003864e-07, 4.87420307e-04,\n",
       "        8.01251145e-04, 8.17605410e-07]),\n",
       " 'mean_score_time': array([0.01216459, 0.01156874, 0.01415677, 0.01077099, 0.01097407,\n",
       "        0.01316533, 0.01077147, 0.00957398, 0.01037292, 0.01076674,\n",
       "        0.0099689 , 0.01037188, 0.00997343, 0.01117587, 0.01097088,\n",
       "        0.01037254, 0.00997319, 0.0121676 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01037245, 0.01017299, 0.01236739, 0.01156893,\n",
       "        0.01216779, 0.01037207, 0.01057262, 0.00997272, 0.00997314,\n",
       "        0.01176877, 0.01136913, 0.0099731 , 0.01077218, 0.01116991,\n",
       "        0.01216693, 0.01116638, 0.01177096, 0.01157064]),\n",
       " 'std_score_time': array([0.00075178, 0.0014925 , 0.00291819, 0.00097718, 0.00155136,\n",
       "        0.0049425 , 0.00074615, 0.00048934, 0.00048946, 0.00171789,\n",
       "        0.00063088, 0.00079789, 0.00063068, 0.00039627, 0.00209167,\n",
       "        0.00079732, 0.00089202, 0.00116264, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00101687, 0.00039845, 0.0016209 , 0.00149313,\n",
       "        0.00263082, 0.00101664, 0.00119629, 0.00063022, 0.00063113,\n",
       "        0.00159552, 0.00331377, 0.00063098, 0.00097679, 0.00116274,\n",
       "        0.00342015, 0.00146221, 0.00311925, 0.00135162]),\n",
       " 'param_class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'dict', 'dict', 'dict', 'dict',\n",
       "                    'dict', 'dict', 'dict', 'dict', 'dict', 'dict', 'dict',\n",
       "                    'dict', 'dict', 'dict', 'dict', 'dict', 'dict', 'dict',\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[None, None, 'sqrt', 'sqrt', 'log2', 'log2', None, None,\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', None, None, 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', None, None, 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', None, None, 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', None, None, 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    None, None, 'sqrt', 'sqrt', 'log2', 'log2', None, None,\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', None, None, 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_splitter': masked_array(data=['best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'}],\n",
       " 'split0_test_score': array([0.96296296, 0.92592593, 0.96328363, 0.98156912, 1.        ,\n",
       "        0.98156912, 0.96296296, 0.98156912, 0.98156912, 0.98156912,\n",
       "        0.94510038, 0.96328363, 0.98156912, 0.96328363, 0.98137826,\n",
       "        0.96328363, 0.98156912, 0.98156912,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.94470736, 0.98156912, 1.        , 0.96328363,\n",
       "        0.98156912, 0.96328363, 0.89075892, 0.98156912, 0.96296296,\n",
       "        1.        , 0.90689128, 0.98156912, 0.89075892, 1.        ,\n",
       "        1.        , 1.        , 0.98156912, 0.94510038]),\n",
       " 'split1_test_score': array([0.9421662 , 0.94304148, 0.96175502, 0.98101383, 0.92351003,\n",
       "        0.94304148, 0.96175502, 0.96226415, 0.96175502, 0.94304148,\n",
       "        0.9436995 , 0.98123317, 0.92351003, 0.98123317, 0.9421662 ,\n",
       "        0.96175502, 0.92351003, 0.94304148,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.96175502, 0.92351003, 0.9245283 , 0.96175502,\n",
       "        0.98101383, 0.96175502, 0.9421662 , 0.96226415, 0.94304148,\n",
       "        0.94304148, 0.96175502, 0.94304148, 0.92218523, 0.96263579,\n",
       "        0.92351003, 0.98101383, 0.98101383, 0.9245283 ]),\n",
       " 'split2_test_score': array([0.962573  , 0.98121703, 0.962573  , 0.98121703, 0.90703509,\n",
       "        0.98121703, 0.92552426, 0.98121703, 0.925146  , 0.9436511 ,\n",
       "        0.94402307, 0.88851518, 0.92552426, 1.        , 0.962573  ,\n",
       "        0.94402307, 0.92552426, 0.98121703,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.962573  , 1.        , 0.92552426, 0.98121703,\n",
       "        0.94402307, 0.98121703, 0.94402307, 1.        , 0.92552426,\n",
       "        0.98121703, 0.962573  , 0.9436511 , 0.962573  , 1.        ,\n",
       "        0.98121703, 0.925146  , 0.90670511, 0.962573  ]),\n",
       " 'split3_test_score': array([0.94309295, 0.94402307, 0.96226415, 0.98103098, 0.94309295,\n",
       "        0.96182604, 0.92249176, 1.        , 0.92249176, 0.98121703,\n",
       "        0.942332  , 0.98121703, 0.92249176, 0.9436511 , 0.92365208,\n",
       "        1.        , 0.942332  , 0.96226415,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.90388666, 0.98121703, 0.92249176, 0.98103098,\n",
       "        0.94402307, 0.98121703, 0.92249176, 0.9436511 , 0.942332  ,\n",
       "        0.98121703, 0.96226415, 0.94309295, 0.92249176, 0.962573  ,\n",
       "        0.96226415, 0.98121703, 0.94309295, 0.98121703]),\n",
       " 'split4_test_score': array([0.98103098, 0.98103098, 0.96226415, 1.        , 0.96226415,\n",
       "        0.98121703, 0.96182604, 0.98121703, 0.98103098, 0.9436511 ,\n",
       "        0.9436511 , 0.96226415, 0.96182604, 0.94402307, 0.94309295,\n",
       "        0.962573  , 0.96226415, 0.9436511 ,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.98103098, 0.98103098, 0.96182604, 0.98121703,\n",
       "        0.94309295, 0.92365208, 0.96226415, 0.94309295, 0.94309295,\n",
       "        0.98121703, 1.        , 0.98121703, 0.96226415, 0.98103098,\n",
       "        0.92365208, 1.        , 1.        , 0.90608517]),\n",
       " 'mean_test_score': array([0.95836522, 0.9550477 , 0.96242799, 0.98496619, 0.94718045,\n",
       "        0.96977414, 0.94691201, 0.98125347, 0.95439858, 0.95862597,\n",
       "        0.94376121, 0.95530263, 0.94298424, 0.96643819, 0.9505725 ,\n",
       "        0.96632694, 0.94703991, 0.96234858,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.9507906 , 0.97346543, 0.94687407, 0.97370074,\n",
       "        0.95874441, 0.96222496, 0.93234082, 0.96611547, 0.94339073,\n",
       "        0.97733852, 0.95869669, 0.95851434, 0.93205461, 0.98124796,\n",
       "        0.95812866, 0.97747537, 0.9624762 , 0.94390078]),\n",
       " 'std_test_score': array([0.01447917, 0.02224291, 0.00050194, 0.00751956, 0.03226785,\n",
       "        0.01535453, 0.01873051, 0.01193423, 0.0259823 , 0.01859093,\n",
       "        0.0008855 , 0.03439963, 0.02428104, 0.02180333, 0.01971966,\n",
       "        0.01830625, 0.02219363, 0.01701655,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.02611708, 0.02601007, 0.03031689, 0.00914263,\n",
       "        0.01841357, 0.02102668, 0.02430834, 0.02207484, 0.01186267,\n",
       "        0.01862771, 0.02975523, 0.01868197, 0.02734292, 0.01672419,\n",
       "        0.03062831, 0.027494  , 0.0334734 , 0.02663797]),\n",
       " 'rank_test_score': array([20, 23, 13,  1, 27,  8, 29,  2, 24, 18, 32, 22, 34,  9, 26, 10, 28,\n",
       "        14, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 25,  7, 30,  6, 16, 15, 35, 11, 33,  5, 17, 19, 36,  3, 21,\n",
       "         4, 12, 31])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76175f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "re=grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "730d34e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007982</td>\n",
       "      <td>1.888718e-03</td>\n",
       "      <td>0.012165</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.943093</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.958365</td>\n",
       "      <td>0.014479</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005586</td>\n",
       "      <td>7.976772e-04</td>\n",
       "      <td>0.011569</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.943041</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.955048</td>\n",
       "      <td>0.022243</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004789</td>\n",
       "      <td>3.999414e-04</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>3.988992e-04</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.981014</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984966</td>\n",
       "      <td>0.007520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>4.000670e-04</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923510</td>\n",
       "      <td>0.907035</td>\n",
       "      <td>0.943093</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.947180</td>\n",
       "      <td>0.032268</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>3.989466e-04</td>\n",
       "      <td>0.013165</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.943041</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.961826</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.969774</td>\n",
       "      <td>0.015355</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005982</td>\n",
       "      <td>1.545359e-03</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.925524</td>\n",
       "      <td>0.922492</td>\n",
       "      <td>0.961826</td>\n",
       "      <td>0.946912</td>\n",
       "      <td>0.018731</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004985</td>\n",
       "      <td>1.996382e-03</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981253</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>9.767864e-04</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.925146</td>\n",
       "      <td>0.922492</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.954399</td>\n",
       "      <td>0.025982</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003997</td>\n",
       "      <td>1.085816e-03</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.943041</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.958626</td>\n",
       "      <td>0.018591</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003794</td>\n",
       "      <td>4.010464e-04</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.945100</td>\n",
       "      <td>0.943699</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>0.942332</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.943761</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003387</td>\n",
       "      <td>8.001200e-04</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.888515</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.955303</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006582</td>\n",
       "      <td>2.720579e-03</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.923510</td>\n",
       "      <td>0.925524</td>\n",
       "      <td>0.922492</td>\n",
       "      <td>0.961826</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>0.024281</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003989</td>\n",
       "      <td>6.314297e-04</td>\n",
       "      <td>0.011176</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>0.966438</td>\n",
       "      <td>0.021803</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003990</td>\n",
       "      <td>6.300725e-04</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.981378</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.923652</td>\n",
       "      <td>0.943093</td>\n",
       "      <td>0.950572</td>\n",
       "      <td>0.019720</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003391</td>\n",
       "      <td>4.891619e-04</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.966327</td>\n",
       "      <td>0.018306</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>1.197100e-03</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.923510</td>\n",
       "      <td>0.925524</td>\n",
       "      <td>0.942332</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.947040</td>\n",
       "      <td>0.022194</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.003990</td>\n",
       "      <td>2.611745e-07</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.943041</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.962349</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>7.893059e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>9.221592e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000798</td>\n",
       "      <td>3.991132e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>7.629395e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000993</td>\n",
       "      <td>9.902382e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>6.641573e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>4.882273e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>3.986365e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000598</td>\n",
       "      <td>4.880735e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>3.984474e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000398</td>\n",
       "      <td>4.880546e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>4.891034e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000598</td>\n",
       "      <td>4.885003e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000790</td>\n",
       "      <td>3.950366e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>4.888898e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>3.985431e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>3.991127e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>4.888897e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.004181</td>\n",
       "      <td>3.919163e-04</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.944707</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.903887</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.950791</td>\n",
       "      <td>0.026117</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.002992</td>\n",
       "      <td>6.975526e-07</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.923510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.973465</td>\n",
       "      <td>0.026010</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.002791</td>\n",
       "      <td>7.459747e-04</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.925524</td>\n",
       "      <td>0.922492</td>\n",
       "      <td>0.961826</td>\n",
       "      <td>0.946874</td>\n",
       "      <td>0.030317</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.002993</td>\n",
       "      <td>6.311289e-04</td>\n",
       "      <td>0.011569</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.973701</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003192</td>\n",
       "      <td>3.981831e-04</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.981014</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>0.943093</td>\n",
       "      <td>0.958744</td>\n",
       "      <td>0.018414</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.003989</td>\n",
       "      <td>8.916968e-04</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.923652</td>\n",
       "      <td>0.962225</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.004391</td>\n",
       "      <td>4.947426e-04</td>\n",
       "      <td>0.010573</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.890759</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>0.922492</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.932341</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.003987</td>\n",
       "      <td>1.996472e-03</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.943093</td>\n",
       "      <td>0.966115</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002993</td>\n",
       "      <td>3.814697e-07</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.943041</td>\n",
       "      <td>0.925524</td>\n",
       "      <td>0.942332</td>\n",
       "      <td>0.943093</td>\n",
       "      <td>0.943391</td>\n",
       "      <td>0.011863</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.003389</td>\n",
       "      <td>4.907177e-04</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943041</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.977339</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.003790</td>\n",
       "      <td>3.986363e-04</td>\n",
       "      <td>0.011369</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.906891</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958697</td>\n",
       "      <td>0.029755</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.003790</td>\n",
       "      <td>7.465824e-04</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.943041</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.943093</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.958514</td>\n",
       "      <td>0.018682</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.004385</td>\n",
       "      <td>4.907697e-04</td>\n",
       "      <td>0.010772</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.890759</td>\n",
       "      <td>0.922185</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.922492</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.932055</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.003989</td>\n",
       "      <td>1.545018e-03</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.981248</td>\n",
       "      <td>0.016724</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.002992</td>\n",
       "      <td>5.840039e-07</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923510</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.923652</td>\n",
       "      <td>0.958129</td>\n",
       "      <td>0.030628</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.003394</td>\n",
       "      <td>4.874203e-04</td>\n",
       "      <td>0.011166</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981014</td>\n",
       "      <td>0.925146</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977475</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.003586</td>\n",
       "      <td>8.012511e-04</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.981014</td>\n",
       "      <td>0.906705</td>\n",
       "      <td>0.943093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962476</td>\n",
       "      <td>0.033473</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.002991</td>\n",
       "      <td>8.176054e-07</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.945100</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.906085</td>\n",
       "      <td>0.943901</td>\n",
       "      <td>0.026638</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.007982  1.888718e-03         0.012165        0.000752   \n",
       "1        0.005586  7.976772e-04         0.011569        0.001493   \n",
       "2        0.004789  3.999414e-04         0.014157        0.002918   \n",
       "3        0.004189  3.988992e-04         0.010771        0.000977   \n",
       "4        0.004189  4.000670e-04         0.010974        0.001551   \n",
       "5        0.004189  3.989466e-04         0.013165        0.004942   \n",
       "6        0.005982  1.545359e-03         0.010771        0.000746   \n",
       "7        0.004985  1.996382e-03         0.009574        0.000489   \n",
       "8        0.004189  9.767864e-04         0.010373        0.000489   \n",
       "9        0.003997  1.085816e-03         0.010767        0.001718   \n",
       "10       0.003794  4.010464e-04         0.009969        0.000631   \n",
       "11       0.003387  8.001200e-04         0.010372        0.000798   \n",
       "12       0.006582  2.720579e-03         0.009973        0.000631   \n",
       "13       0.003989  6.314297e-04         0.011176        0.000396   \n",
       "14       0.003990  6.300725e-04         0.010971        0.002092   \n",
       "15       0.003391  4.891619e-04         0.010373        0.000797   \n",
       "16       0.004588  1.197100e-03         0.009973        0.000892   \n",
       "17       0.003990  2.611745e-07         0.012168        0.001163   \n",
       "18       0.000998  7.893059e-07         0.000000        0.000000   \n",
       "19       0.000997  9.221592e-07         0.000000        0.000000   \n",
       "20       0.000798  3.991132e-04         0.000000        0.000000   \n",
       "21       0.000998  7.629395e-07         0.000000        0.000000   \n",
       "22       0.000993  9.902382e-06         0.000000        0.000000   \n",
       "23       0.000997  6.641573e-07         0.000000        0.000000   \n",
       "24       0.000399  4.882273e-04         0.000000        0.000000   \n",
       "25       0.000797  3.986365e-04         0.000000        0.000000   \n",
       "26       0.000598  4.880735e-04         0.000000        0.000000   \n",
       "27       0.000797  3.984474e-04         0.000000        0.000000   \n",
       "28       0.000398  4.880546e-04         0.000000        0.000000   \n",
       "29       0.000399  4.891034e-04         0.000000        0.000000   \n",
       "30       0.000598  4.885003e-04         0.000000        0.000000   \n",
       "31       0.000790  3.950366e-04         0.000000        0.000000   \n",
       "32       0.000599  4.888898e-04         0.000000        0.000000   \n",
       "33       0.000797  3.985431e-04         0.000000        0.000000   \n",
       "34       0.000200  3.991127e-04         0.000000        0.000000   \n",
       "35       0.000599  4.888897e-04         0.000000        0.000000   \n",
       "36       0.004181  3.919163e-04         0.010372        0.001017   \n",
       "37       0.002992  6.975526e-07         0.010173        0.000398   \n",
       "38       0.002791  7.459747e-04         0.012367        0.001621   \n",
       "39       0.002993  6.311289e-04         0.011569        0.001493   \n",
       "40       0.003192  3.981831e-04         0.012168        0.002631   \n",
       "41       0.003989  8.916968e-04         0.010372        0.001017   \n",
       "42       0.004391  4.947426e-04         0.010573        0.001196   \n",
       "43       0.003987  1.996472e-03         0.009973        0.000630   \n",
       "44       0.002993  3.814697e-07         0.009973        0.000631   \n",
       "45       0.003389  4.907177e-04         0.011769        0.001596   \n",
       "46       0.003790  3.986363e-04         0.011369        0.003314   \n",
       "47       0.003790  7.465824e-04         0.009973        0.000631   \n",
       "48       0.004385  4.907697e-04         0.010772        0.000977   \n",
       "49       0.003989  1.545018e-03         0.011170        0.001163   \n",
       "50       0.002992  5.840039e-07         0.012167        0.003420   \n",
       "51       0.003394  4.874203e-04         0.011166        0.001462   \n",
       "52       0.003586  8.012511e-04         0.011771        0.003119   \n",
       "53       0.002991  8.176054e-07         0.011571        0.001352   \n",
       "\n",
       "   param_class_weight param_criterion param_max_features param_splitter  \\\n",
       "0            balanced            gini               None           best   \n",
       "1            balanced            gini               None         random   \n",
       "2            balanced            gini               sqrt           best   \n",
       "3            balanced            gini               sqrt         random   \n",
       "4            balanced            gini               log2           best   \n",
       "5            balanced            gini               log2         random   \n",
       "6            balanced         entropy               None           best   \n",
       "7            balanced         entropy               None         random   \n",
       "8            balanced         entropy               sqrt           best   \n",
       "9            balanced         entropy               sqrt         random   \n",
       "10           balanced         entropy               log2           best   \n",
       "11           balanced         entropy               log2         random   \n",
       "12           balanced        log_loss               None           best   \n",
       "13           balanced        log_loss               None         random   \n",
       "14           balanced        log_loss               sqrt           best   \n",
       "15           balanced        log_loss               sqrt         random   \n",
       "16           balanced        log_loss               log2           best   \n",
       "17           balanced        log_loss               log2         random   \n",
       "18               dict            gini               None           best   \n",
       "19               dict            gini               None         random   \n",
       "20               dict            gini               sqrt           best   \n",
       "21               dict            gini               sqrt         random   \n",
       "22               dict            gini               log2           best   \n",
       "23               dict            gini               log2         random   \n",
       "24               dict         entropy               None           best   \n",
       "25               dict         entropy               None         random   \n",
       "26               dict         entropy               sqrt           best   \n",
       "27               dict         entropy               sqrt         random   \n",
       "28               dict         entropy               log2           best   \n",
       "29               dict         entropy               log2         random   \n",
       "30               dict        log_loss               None           best   \n",
       "31               dict        log_loss               None         random   \n",
       "32               dict        log_loss               sqrt           best   \n",
       "33               dict        log_loss               sqrt         random   \n",
       "34               dict        log_loss               log2           best   \n",
       "35               dict        log_loss               log2         random   \n",
       "36               None            gini               None           best   \n",
       "37               None            gini               None         random   \n",
       "38               None            gini               sqrt           best   \n",
       "39               None            gini               sqrt         random   \n",
       "40               None            gini               log2           best   \n",
       "41               None            gini               log2         random   \n",
       "42               None         entropy               None           best   \n",
       "43               None         entropy               None         random   \n",
       "44               None         entropy               sqrt           best   \n",
       "45               None         entropy               sqrt         random   \n",
       "46               None         entropy               log2           best   \n",
       "47               None         entropy               log2         random   \n",
       "48               None        log_loss               None           best   \n",
       "49               None        log_loss               None         random   \n",
       "50               None        log_loss               sqrt           best   \n",
       "51               None        log_loss               sqrt         random   \n",
       "52               None        log_loss               log2           best   \n",
       "53               None        log_loss               log2         random   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'class_weight': 'balanced', 'criterion': 'gin...           0.962963   \n",
       "1   {'class_weight': 'balanced', 'criterion': 'gin...           0.925926   \n",
       "2   {'class_weight': 'balanced', 'criterion': 'gin...           0.963284   \n",
       "3   {'class_weight': 'balanced', 'criterion': 'gin...           0.981569   \n",
       "4   {'class_weight': 'balanced', 'criterion': 'gin...           1.000000   \n",
       "5   {'class_weight': 'balanced', 'criterion': 'gin...           0.981569   \n",
       "6   {'class_weight': 'balanced', 'criterion': 'ent...           0.962963   \n",
       "7   {'class_weight': 'balanced', 'criterion': 'ent...           0.981569   \n",
       "8   {'class_weight': 'balanced', 'criterion': 'ent...           0.981569   \n",
       "9   {'class_weight': 'balanced', 'criterion': 'ent...           0.981569   \n",
       "10  {'class_weight': 'balanced', 'criterion': 'ent...           0.945100   \n",
       "11  {'class_weight': 'balanced', 'criterion': 'ent...           0.963284   \n",
       "12  {'class_weight': 'balanced', 'criterion': 'log...           0.981569   \n",
       "13  {'class_weight': 'balanced', 'criterion': 'log...           0.963284   \n",
       "14  {'class_weight': 'balanced', 'criterion': 'log...           0.981378   \n",
       "15  {'class_weight': 'balanced', 'criterion': 'log...           0.963284   \n",
       "16  {'class_weight': 'balanced', 'criterion': 'log...           0.981569   \n",
       "17  {'class_weight': 'balanced', 'criterion': 'log...           0.981569   \n",
       "18  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "19  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "20  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "21  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "22  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "23  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "24  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "25  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "26  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "27  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "28  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "29  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "30  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "31  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "32  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "33  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "34  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "35  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "36  {'class_weight': None, 'criterion': 'gini', 'm...           0.944707   \n",
       "37  {'class_weight': None, 'criterion': 'gini', 'm...           0.981569   \n",
       "38  {'class_weight': None, 'criterion': 'gini', 'm...           1.000000   \n",
       "39  {'class_weight': None, 'criterion': 'gini', 'm...           0.963284   \n",
       "40  {'class_weight': None, 'criterion': 'gini', 'm...           0.981569   \n",
       "41  {'class_weight': None, 'criterion': 'gini', 'm...           0.963284   \n",
       "42  {'class_weight': None, 'criterion': 'entropy',...           0.890759   \n",
       "43  {'class_weight': None, 'criterion': 'entropy',...           0.981569   \n",
       "44  {'class_weight': None, 'criterion': 'entropy',...           0.962963   \n",
       "45  {'class_weight': None, 'criterion': 'entropy',...           1.000000   \n",
       "46  {'class_weight': None, 'criterion': 'entropy',...           0.906891   \n",
       "47  {'class_weight': None, 'criterion': 'entropy',...           0.981569   \n",
       "48  {'class_weight': None, 'criterion': 'log_loss'...           0.890759   \n",
       "49  {'class_weight': None, 'criterion': 'log_loss'...           1.000000   \n",
       "50  {'class_weight': None, 'criterion': 'log_loss'...           1.000000   \n",
       "51  {'class_weight': None, 'criterion': 'log_loss'...           1.000000   \n",
       "52  {'class_weight': None, 'criterion': 'log_loss'...           0.981569   \n",
       "53  {'class_weight': None, 'criterion': 'log_loss'...           0.945100   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.942166           0.962573           0.943093   \n",
       "1            0.943041           0.981217           0.944023   \n",
       "2            0.961755           0.962573           0.962264   \n",
       "3            0.981014           0.981217           0.981031   \n",
       "4            0.923510           0.907035           0.943093   \n",
       "5            0.943041           0.981217           0.961826   \n",
       "6            0.961755           0.925524           0.922492   \n",
       "7            0.962264           0.981217           1.000000   \n",
       "8            0.961755           0.925146           0.922492   \n",
       "9            0.943041           0.943651           0.981217   \n",
       "10           0.943699           0.944023           0.942332   \n",
       "11           0.981233           0.888515           0.981217   \n",
       "12           0.923510           0.925524           0.922492   \n",
       "13           0.981233           1.000000           0.943651   \n",
       "14           0.942166           0.962573           0.923652   \n",
       "15           0.961755           0.944023           1.000000   \n",
       "16           0.923510           0.925524           0.942332   \n",
       "17           0.943041           0.981217           0.962264   \n",
       "18                NaN                NaN                NaN   \n",
       "19                NaN                NaN                NaN   \n",
       "20                NaN                NaN                NaN   \n",
       "21                NaN                NaN                NaN   \n",
       "22                NaN                NaN                NaN   \n",
       "23                NaN                NaN                NaN   \n",
       "24                NaN                NaN                NaN   \n",
       "25                NaN                NaN                NaN   \n",
       "26                NaN                NaN                NaN   \n",
       "27                NaN                NaN                NaN   \n",
       "28                NaN                NaN                NaN   \n",
       "29                NaN                NaN                NaN   \n",
       "30                NaN                NaN                NaN   \n",
       "31                NaN                NaN                NaN   \n",
       "32                NaN                NaN                NaN   \n",
       "33                NaN                NaN                NaN   \n",
       "34                NaN                NaN                NaN   \n",
       "35                NaN                NaN                NaN   \n",
       "36           0.961755           0.962573           0.903887   \n",
       "37           0.923510           1.000000           0.981217   \n",
       "38           0.924528           0.925524           0.922492   \n",
       "39           0.961755           0.981217           0.981031   \n",
       "40           0.981014           0.944023           0.944023   \n",
       "41           0.961755           0.981217           0.981217   \n",
       "42           0.942166           0.944023           0.922492   \n",
       "43           0.962264           1.000000           0.943651   \n",
       "44           0.943041           0.925524           0.942332   \n",
       "45           0.943041           0.981217           0.981217   \n",
       "46           0.961755           0.962573           0.962264   \n",
       "47           0.943041           0.943651           0.943093   \n",
       "48           0.922185           0.962573           0.922492   \n",
       "49           0.962636           1.000000           0.962573   \n",
       "50           0.923510           0.981217           0.962264   \n",
       "51           0.981014           0.925146           0.981217   \n",
       "52           0.981014           0.906705           0.943093   \n",
       "53           0.924528           0.962573           0.981217   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.981031         0.958365        0.014479               20  \n",
       "1            0.981031         0.955048        0.022243               23  \n",
       "2            0.962264         0.962428        0.000502               13  \n",
       "3            1.000000         0.984966        0.007520                1  \n",
       "4            0.962264         0.947180        0.032268               27  \n",
       "5            0.981217         0.969774        0.015355                8  \n",
       "6            0.961826         0.946912        0.018731               29  \n",
       "7            0.981217         0.981253        0.011934                2  \n",
       "8            0.981031         0.954399        0.025982               24  \n",
       "9            0.943651         0.958626        0.018591               18  \n",
       "10           0.943651         0.943761        0.000885               32  \n",
       "11           0.962264         0.955303        0.034400               22  \n",
       "12           0.961826         0.942984        0.024281               34  \n",
       "13           0.944023         0.966438        0.021803                9  \n",
       "14           0.943093         0.950572        0.019720               26  \n",
       "15           0.962573         0.966327        0.018306               10  \n",
       "16           0.962264         0.947040        0.022194               28  \n",
       "17           0.943651         0.962349        0.017017               14  \n",
       "18                NaN              NaN             NaN               37  \n",
       "19                NaN              NaN             NaN               37  \n",
       "20                NaN              NaN             NaN               37  \n",
       "21                NaN              NaN             NaN               37  \n",
       "22                NaN              NaN             NaN               37  \n",
       "23                NaN              NaN             NaN               37  \n",
       "24                NaN              NaN             NaN               37  \n",
       "25                NaN              NaN             NaN               37  \n",
       "26                NaN              NaN             NaN               37  \n",
       "27                NaN              NaN             NaN               37  \n",
       "28                NaN              NaN             NaN               37  \n",
       "29                NaN              NaN             NaN               37  \n",
       "30                NaN              NaN             NaN               37  \n",
       "31                NaN              NaN             NaN               37  \n",
       "32                NaN              NaN             NaN               37  \n",
       "33                NaN              NaN             NaN               37  \n",
       "34                NaN              NaN             NaN               37  \n",
       "35                NaN              NaN             NaN               37  \n",
       "36           0.981031         0.950791        0.026117               25  \n",
       "37           0.981031         0.973465        0.026010                7  \n",
       "38           0.961826         0.946874        0.030317               30  \n",
       "39           0.981217         0.973701        0.009143                6  \n",
       "40           0.943093         0.958744        0.018414               16  \n",
       "41           0.923652         0.962225        0.021027               15  \n",
       "42           0.962264         0.932341        0.024308               35  \n",
       "43           0.943093         0.966115        0.022075               11  \n",
       "44           0.943093         0.943391        0.011863               33  \n",
       "45           0.981217         0.977339        0.018628                5  \n",
       "46           1.000000         0.958697        0.029755               17  \n",
       "47           0.981217         0.958514        0.018682               19  \n",
       "48           0.962264         0.932055        0.027343               36  \n",
       "49           0.981031         0.981248        0.016724                3  \n",
       "50           0.923652         0.958129        0.030628               21  \n",
       "51           1.000000         0.977475        0.027494                4  \n",
       "52           1.000000         0.962476        0.033473               12  \n",
       "53           0.906085         0.943901        0.026638               31  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table= pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce041c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849661930849581"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b9547f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.25720128e-01,  1.18386687e+00,  7.43679000e+00,\n",
       "         4.68015545e+00, -3.88079651e-01, -2.48869935e-03,\n",
       "        -2.86774811e-01,  5.15346177e-01, -2.58764074e-01,\n",
       "        -1.75196181e-01,  2.70805503e+00, -1.31927538e-01,\n",
       "         3.97885360e-01, -4.92940822e-01, -5.45491499e-01,\n",
       "        -4.51242628e-01, -1.38409133e-01,  3.89249472e-01,\n",
       "         5.10552159e-01, -3.42997170e-01,  4.24264069e+00,\n",
       "         1.35269628e+00,  1.35269628e+00, -2.92770022e-01,\n",
       "        -1.93649167e+00, -5.22232968e-01, -4.45194562e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_input= sc.transform([[50,92,10,5,120,60,1.5,143,4,12,61,8000,5,0,0,0,0,1,1,0,1,1,1,0,0,0,0]])\n",
    "pre_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1904615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result= grid.predict(pre_input)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619036c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
