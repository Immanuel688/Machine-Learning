{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa03b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3954c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"Social_Network_Ads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9899686b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0    15624510    Male   19            19000          0\n",
       "1    15810944    Male   35            20000          0\n",
       "2    15668575  Female   26            43000          0\n",
       "3    15603246  Female   27            57000          0\n",
       "4    15804002    Male   19            76000          0\n",
       "..        ...     ...  ...              ...        ...\n",
       "395  15691863  Female   46            41000          1\n",
       "396  15706071    Male   51            23000          1\n",
       "397  15654296  Female   50            20000          1\n",
       "398  15755018    Male   36            33000          0\n",
       "399  15594041  Female   49            36000          1\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9eff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e7ff6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Age  EstimatedSalary  Purchased  Gender_Male\n",
       "0    15624510   19            19000          0            1\n",
       "1    15810944   35            20000          0            1\n",
       "2    15668575   26            43000          0            0\n",
       "3    15603246   27            57000          0            0\n",
       "4    15804002   19            76000          0            1\n",
       "..        ...  ...              ...        ...          ...\n",
       "395  15691863   46            41000          1            0\n",
       "396  15706071   51            23000          1            1\n",
       "397  15654296   50            20000          1            0\n",
       "398  15755018   36            33000          0            1\n",
       "399  15594041   49            36000          1            0\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "191c2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep=dataset[[\"Gender_Male\",\"Age\",'EstimatedSalary']]\n",
    "dep=dataset[[\"Purchased\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f9e4796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Purchased\n",
       "0    257\n",
       "1    143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Purchased\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b88eb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(indep,dep,test_size=1/3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d19e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train= sc.fit_transform(X_train)\n",
    "X_test= sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b0fa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "90 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of DecisionTreeClassifier must be an instance of 'dict', an instance of 'list', a str among {'balanced'} or None. Got 'dict' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.87196017 0.8040886  0.83755333 0.81993501 0.84501913 0.79912213\n",
      " 0.85784507 0.86176589 0.84388919 0.80039923 0.84956365 0.8042884\n",
      " 0.86862347 0.86097819 0.84544129 0.83889474 0.8302234  0.81626422\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.8574852  0.84326532 0.83643814 0.84183578 0.84140447 0.79418513\n",
      " 0.88016579 0.85303579 0.86768302 0.83000169 0.85638323 0.82214914\n",
      " 0.86870843 0.84179287 0.82505588 0.81346058 0.82106059 0.85676568]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, &#x27;dict&#x27;, None],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, &#x27;dict&#x27;, None],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', 'dict', None],\n",
       "                         'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': [None, 'sqrt', 'log2'],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "param_grid={'criterion':[\"gini\", \"entropy\", \"log_loss\"], 'splitter': [\"best\", \"random\"], 'class_weight': ['balanced', 'dict', None], 'max_features': [None,\"sqrt\", \"log2\"]}\n",
    "grid= GridSearchCV(DecisionTreeClassifier(), param_grid, refit= True, verbose=3, n_jobs=-1, scoring= 'f1_weighted' )\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a3a7775",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffcba057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76,  9],\n",
       "       [ 8, 41]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5438959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf_report=classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bffd0601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90        85\n",
      "           1       0.82      0.84      0.83        49\n",
      "\n",
      "    accuracy                           0.87       134\n",
      "   macro avg       0.86      0.87      0.86       134\n",
      "weighted avg       0.87      0.87      0.87       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99a71947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8654261704681873"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_score= roc_auc_score(y_test,grid.predict_proba(X_test)[:,1])\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4117b642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the best parameter is  {'class_weight': None, 'criterion': 'entropy', 'max_features': None, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "print ( \" the best parameter is \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd902e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00657864, 0.00517993, 0.00658264, 0.00518355, 0.0057795 ,\n",
       "        0.00698047, 0.00617657, 0.0035881 , 0.00438867, 0.00458755,\n",
       "        0.00458851, 0.00479188, 0.00398989, 0.00418944, 0.00399027,\n",
       "        0.00379176, 0.00398598, 0.00418921, 0.00100021, 0.00059819,\n",
       "        0.00079846, 0.00079799, 0.00079856, 0.00039887, 0.00080366,\n",
       "        0.00059876, 0.00039907, 0.00079799, 0.00079923, 0.0009995 ,\n",
       "        0.00099778, 0.00079794, 0.00119915, 0.00099506, 0.00100088,\n",
       "        0.00120015, 0.00418892, 0.00378928, 0.00299039, 0.00339212,\n",
       "        0.0031919 , 0.00359025, 0.00378633, 0.00339174, 0.00378957,\n",
       "        0.00418892, 0.00318666, 0.00359063, 0.00358791, 0.00319114,\n",
       "        0.00439215, 0.00538979, 0.00438805, 0.00319147]),\n",
       " 'std_fit_time': array([1.19833762e-03, 7.40357731e-04, 1.73939697e-03, 1.16971454e-03,\n",
       "        9.75703734e-04, 2.81770263e-03, 7.45108215e-04, 4.87288909e-04,\n",
       "        4.89220112e-04, 1.35237434e-03, 7.97879858e-04, 1.16386820e-03,\n",
       "        4.62310777e-07, 1.46631067e-03, 6.67572021e-07, 3.97898635e-04,\n",
       "        6.31609482e-04, 3.99494456e-04, 6.31155385e-04, 4.88422418e-04,\n",
       "        3.99232605e-04, 3.98994101e-04, 3.99280374e-04, 4.88519703e-04,\n",
       "        4.01890436e-04, 4.88890411e-04, 4.88752886e-04, 3.98995098e-04,\n",
       "        3.99616065e-04, 6.30700658e-04, 1.14837595e-06, 7.46149437e-04,\n",
       "        9.76395274e-04, 6.19631494e-06, 1.21223598e-05, 3.97744746e-04,\n",
       "        4.00471953e-04, 1.16141296e-03, 4.56520220e-06, 4.88987022e-04,\n",
       "        9.77243122e-04, 7.97939457e-04, 7.49432524e-04, 4.88617412e-04,\n",
       "        7.45435468e-04, 2.03369024e-03, 4.00778026e-04, 7.97832420e-04,\n",
       "        7.98862618e-04, 3.97849579e-04, 1.95506931e-03, 3.37268694e-03,\n",
       "        1.95372178e-03, 3.99351618e-04]),\n",
       " 'mean_score_time': array([0.01496005, 0.01256666, 0.02015033, 0.01475611, 0.01675944,\n",
       "        0.01516261, 0.01535873, 0.01096983, 0.01057181, 0.01176848,\n",
       "        0.01096997, 0.01096568, 0.01017275, 0.01077056, 0.00957961,\n",
       "        0.01017451, 0.01097126, 0.01196785, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0113699 , 0.00957117, 0.01097054, 0.01017199,\n",
       "        0.01057301, 0.01117001, 0.0115696 , 0.00997348, 0.01077666,\n",
       "        0.0103744 , 0.01097584, 0.00997763, 0.01236749, 0.01037273,\n",
       "        0.01056724, 0.01076784, 0.01156998, 0.01097331]),\n",
       " 'std_score_time': array([3.56765340e-03, 1.84980742e-03, 4.56790794e-03, 1.93994425e-03,\n",
       "        3.11580558e-03, 1.71470139e-03, 2.56954207e-03, 1.11216581e-06,\n",
       "        1.19562181e-03, 3.11528667e-03, 1.09301564e-03, 6.23837739e-04,\n",
       "        9.77447340e-04, 7.46034814e-04, 4.92865364e-04, 1.16741240e-03,\n",
       "        1.09266903e-03, 1.09266726e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.35273323e-03, 4.85809564e-04, 1.54449538e-03, 7.46200359e-04,\n",
       "        1.19527159e-03, 7.46136367e-04, 2.79330869e-03, 6.30449711e-04,\n",
       "        1.16388166e-03, 8.01635092e-04, 6.30841107e-04, 8.80200580e-06,\n",
       "        2.93257546e-03, 1.01773892e-03, 7.95314785e-04, 1.58779631e-03,\n",
       "        1.49340722e-03, 1.54254080e-03]),\n",
       " 'param_class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'dict', 'dict', 'dict', 'dict',\n",
       "                    'dict', 'dict', 'dict', 'dict', 'dict', 'dict', 'dict',\n",
       "                    'dict', 'dict', 'dict', 'dict', 'dict', 'dict', 'dict',\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[None, None, 'sqrt', 'sqrt', 'log2', 'log2', None, None,\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', None, None, 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', None, None, 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', None, None, 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', None, None, 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    None, None, 'sqrt', 'sqrt', 'log2', 'log2', None, None,\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', None, None, 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_splitter': masked_array(data=['best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'balanced',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': 'dict',\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'entropy',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': None,\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'sqrt',\n",
       "   'splitter': 'random'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'best'},\n",
       "  {'class_weight': None,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_features': 'log2',\n",
       "   'splitter': 'random'}],\n",
       " 'split0_test_score': array([0.82626263, 0.80892657, 0.84714126, 0.79962013, 0.82626263,\n",
       "        0.74302161, 0.83225479, 0.88535594, 0.82626263, 0.79175183,\n",
       "        0.84714126, 0.80892657, 0.82961513, 0.8122428 , 0.84714126,\n",
       "        0.83225479, 0.82626263, 0.80892657,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.82961513, 0.80476365, 0.78255675, 0.82961513,\n",
       "        0.88734568, 0.74904602, 0.84979424, 0.86747844, 0.84381092,\n",
       "        0.8122428 , 0.80476365, 0.8122428 , 0.8122428 , 0.80892657,\n",
       "        0.80892657, 0.8695315 , 0.82209189, 0.86747844]),\n",
       " 'split1_test_score': array([0.86875226, 0.81132075, 0.84671353, 0.81132075, 0.87004744,\n",
       "        0.85080904, 0.8490566 , 0.8159535 , 0.83125291, 0.79094947,\n",
       "        0.85080904, 0.81132075, 0.86875226, 0.8135113 , 0.81132075,\n",
       "        0.85080904, 0.83125291, 0.81503716,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.8490566 , 0.79094947, 0.8135113 , 0.8490566 ,\n",
       "        0.8135113 , 0.77358491, 0.86875226, 0.81132075, 0.8490566 ,\n",
       "        0.8135113 , 0.85080904, 0.80462774, 0.86875226, 0.87004744,\n",
       "        0.81132075, 0.86875226, 0.83125291, 0.8490566 ]),\n",
       " 'split2_test_score': array([0.83332289, 0.77581475, 0.81440925, 0.81317896, 0.81440925,\n",
       "        0.74017296, 0.83248257, 0.83248257, 0.85054317, 0.79356483,\n",
       "        0.81317896, 0.77806673, 0.81440925, 0.8310985 , 0.79668694,\n",
       "        0.79525647, 0.79628353, 0.75924417,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.83332289, 0.85054317, 0.83248257, 0.74017296,\n",
       "        0.85054317, 0.74017296, 0.83248257, 0.83248257, 0.81505561,\n",
       "        0.83248257, 0.75803037, 0.73845054, 0.85054317, 0.79668694,\n",
       "        0.79356483, 0.72275492, 0.81440925, 0.75803037]),\n",
       " 'split3_test_score': array([0.90693476, 0.79525647, 0.83248257, 0.8490566 , 0.8310985 ,\n",
       "        0.83248257, 0.87036224, 0.8515274 , 0.87036224, 0.81440925,\n",
       "        0.81317896, 0.86709679, 0.92527158, 0.9245283 , 0.88679245,\n",
       "        0.86709679, 0.90616583, 0.8490566 ,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.87036224, 0.88679245, 0.87036224, 0.90506914,\n",
       "        0.83248257, 0.86709679, 0.92527158, 0.86863217, 0.9436995 ,\n",
       "        0.86863217, 0.92527158, 0.86863217, 0.90693476, 0.9245283 ,\n",
       "        0.86709679, 0.75924417, 0.81440925, 0.86709679]),\n",
       " 'split4_test_score': array([0.9245283 , 0.82912445, 0.84702007, 0.82649861, 0.88327784,\n",
       "        0.82912445, 0.90506914, 0.92351003, 0.84102499, 0.81132075,\n",
       "        0.92351003, 0.75603116, 0.90506914, 0.92351003, 0.88526505,\n",
       "        0.8490566 , 0.7911521 , 0.8490566 ,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.90506914, 0.88327784, 0.88327784, 0.88526505,\n",
       "        0.82313964, 0.84102499, 0.9245283 , 0.88526505, 0.88679245,\n",
       "        0.82313964, 0.94304148, 0.88679245, 0.90506914, 0.80877508,\n",
       "        0.84437045, 0.84702007, 0.82313964, 0.9421662 ]),\n",
       " 'mean_test_score': array([0.87196017, 0.8040886 , 0.83755333, 0.81993501, 0.84501913,\n",
       "        0.79912213, 0.85784507, 0.86176589, 0.84388919, 0.80039923,\n",
       "        0.84956365, 0.8042884 , 0.86862347, 0.86097819, 0.84544129,\n",
       "        0.83889474, 0.8302234 , 0.81626422,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.8574852 , 0.84326532, 0.83643814, 0.84183578,\n",
       "        0.84140447, 0.79418513, 0.88016579, 0.85303579, 0.86768302,\n",
       "        0.83000169, 0.85638323, 0.82214914, 0.86870843, 0.84179287,\n",
       "        0.82505588, 0.81346058, 0.82106059, 0.85676568]),\n",
       " 'std_test_score': array([0.03893078, 0.01777594, 0.01285937, 0.01687419, 0.02673088,\n",
       "        0.0475539 , 0.02743045, 0.03854853, 0.015644  , 0.01026007,\n",
       "        0.04030677, 0.03750253, 0.04242203, 0.05190354, 0.03698632,\n",
       "        0.02444978, 0.04113996, 0.03303729,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.02779082, 0.0394155 , 0.03684913, 0.05730859,\n",
       "        0.02602054, 0.05077264, 0.03828565, 0.02703014, 0.04433992,\n",
       "        0.02065365, 0.0701772 , 0.05244048, 0.03550127, 0.04867933,\n",
       "        0.02676186, 0.06081824, 0.00628888, 0.05886057]),\n",
       " 'rank_test_score': array([ 2, 33, 22, 29, 15, 35,  8,  6, 16, 34, 13, 32,  4,  7, 14, 21, 24,\n",
       "        30, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37,  9, 17, 23, 18, 20, 36,  1, 12,  5, 25, 11, 27,  3, 19, 26,\n",
       "        31, 28, 10])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76175f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "re=grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "730d34e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006579</td>\n",
       "      <td>1.198338e-03</td>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.826263</td>\n",
       "      <td>0.868752</td>\n",
       "      <td>0.833323</td>\n",
       "      <td>0.906935</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.871960</td>\n",
       "      <td>0.038931</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005180</td>\n",
       "      <td>7.403577e-04</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.808927</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.775815</td>\n",
       "      <td>0.795256</td>\n",
       "      <td>0.829124</td>\n",
       "      <td>0.804089</td>\n",
       "      <td>0.017776</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006583</td>\n",
       "      <td>1.739397e-03</td>\n",
       "      <td>0.020150</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.847141</td>\n",
       "      <td>0.846714</td>\n",
       "      <td>0.814409</td>\n",
       "      <td>0.832483</td>\n",
       "      <td>0.847020</td>\n",
       "      <td>0.837553</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005184</td>\n",
       "      <td>1.169715e-03</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.799620</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.813179</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.826499</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>0.016874</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005780</td>\n",
       "      <td>9.757037e-04</td>\n",
       "      <td>0.016759</td>\n",
       "      <td>0.003116</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.826263</td>\n",
       "      <td>0.870047</td>\n",
       "      <td>0.814409</td>\n",
       "      <td>0.831098</td>\n",
       "      <td>0.883278</td>\n",
       "      <td>0.845019</td>\n",
       "      <td>0.026731</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006980</td>\n",
       "      <td>2.817703e-03</td>\n",
       "      <td>0.015163</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.743022</td>\n",
       "      <td>0.850809</td>\n",
       "      <td>0.740173</td>\n",
       "      <td>0.832483</td>\n",
       "      <td>0.829124</td>\n",
       "      <td>0.799122</td>\n",
       "      <td>0.047554</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006177</td>\n",
       "      <td>7.451082e-04</td>\n",
       "      <td>0.015359</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.832255</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.832483</td>\n",
       "      <td>0.870362</td>\n",
       "      <td>0.905069</td>\n",
       "      <td>0.857845</td>\n",
       "      <td>0.027430</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003588</td>\n",
       "      <td>4.872889e-04</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.885356</td>\n",
       "      <td>0.815954</td>\n",
       "      <td>0.832483</td>\n",
       "      <td>0.851527</td>\n",
       "      <td>0.923510</td>\n",
       "      <td>0.861766</td>\n",
       "      <td>0.038549</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004389</td>\n",
       "      <td>4.892201e-04</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.826263</td>\n",
       "      <td>0.831253</td>\n",
       "      <td>0.850543</td>\n",
       "      <td>0.870362</td>\n",
       "      <td>0.841025</td>\n",
       "      <td>0.843889</td>\n",
       "      <td>0.015644</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>1.352374e-03</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.791752</td>\n",
       "      <td>0.790949</td>\n",
       "      <td>0.793565</td>\n",
       "      <td>0.814409</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.800399</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004589</td>\n",
       "      <td>7.978799e-04</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.847141</td>\n",
       "      <td>0.850809</td>\n",
       "      <td>0.813179</td>\n",
       "      <td>0.813179</td>\n",
       "      <td>0.923510</td>\n",
       "      <td>0.849564</td>\n",
       "      <td>0.040307</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004792</td>\n",
       "      <td>1.163868e-03</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.808927</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.778067</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.756031</td>\n",
       "      <td>0.804288</td>\n",
       "      <td>0.037503</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003990</td>\n",
       "      <td>4.623108e-07</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.829615</td>\n",
       "      <td>0.868752</td>\n",
       "      <td>0.814409</td>\n",
       "      <td>0.925272</td>\n",
       "      <td>0.905069</td>\n",
       "      <td>0.868623</td>\n",
       "      <td>0.042422</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>1.466311e-03</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.812243</td>\n",
       "      <td>0.813511</td>\n",
       "      <td>0.831098</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.923510</td>\n",
       "      <td>0.860978</td>\n",
       "      <td>0.051904</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003990</td>\n",
       "      <td>6.675720e-07</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.847141</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.796687</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.885265</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.036986</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003792</td>\n",
       "      <td>3.978986e-04</td>\n",
       "      <td>0.010175</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.832255</td>\n",
       "      <td>0.850809</td>\n",
       "      <td>0.795256</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.838895</td>\n",
       "      <td>0.024450</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003986</td>\n",
       "      <td>6.316095e-04</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.826263</td>\n",
       "      <td>0.831253</td>\n",
       "      <td>0.796284</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.791152</td>\n",
       "      <td>0.830223</td>\n",
       "      <td>0.041140</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>3.994945e-04</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.808927</td>\n",
       "      <td>0.815037</td>\n",
       "      <td>0.759244</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.816264</td>\n",
       "      <td>0.033037</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>6.311554e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000598</td>\n",
       "      <td>4.884224e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000798</td>\n",
       "      <td>3.992326e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000798</td>\n",
       "      <td>3.989941e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000799</td>\n",
       "      <td>3.992804e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>4.885197e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'gini', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000804</td>\n",
       "      <td>4.018904e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>4.888904e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>4.887529e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000798</td>\n",
       "      <td>3.989951e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000799</td>\n",
       "      <td>3.996161e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>6.307007e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'entropy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>1.148376e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000798</td>\n",
       "      <td>7.461494e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001199</td>\n",
       "      <td>9.763953e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000995</td>\n",
       "      <td>6.196315e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>1.212236e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001200</td>\n",
       "      <td>3.977447e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dict</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': 'dict', 'criterion': 'log_los...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>4.004720e-04</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.829615</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.833323</td>\n",
       "      <td>0.870362</td>\n",
       "      <td>0.905069</td>\n",
       "      <td>0.857485</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.003789</td>\n",
       "      <td>1.161413e-03</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.804764</td>\n",
       "      <td>0.790949</td>\n",
       "      <td>0.850543</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.883278</td>\n",
       "      <td>0.843265</td>\n",
       "      <td>0.039415</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.002990</td>\n",
       "      <td>4.565202e-06</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.782557</td>\n",
       "      <td>0.813511</td>\n",
       "      <td>0.832483</td>\n",
       "      <td>0.870362</td>\n",
       "      <td>0.883278</td>\n",
       "      <td>0.836438</td>\n",
       "      <td>0.036849</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.003392</td>\n",
       "      <td>4.889870e-04</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.829615</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.740173</td>\n",
       "      <td>0.905069</td>\n",
       "      <td>0.885265</td>\n",
       "      <td>0.841836</td>\n",
       "      <td>0.057309</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003192</td>\n",
       "      <td>9.772431e-04</td>\n",
       "      <td>0.010573</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.887346</td>\n",
       "      <td>0.813511</td>\n",
       "      <td>0.850543</td>\n",
       "      <td>0.832483</td>\n",
       "      <td>0.823140</td>\n",
       "      <td>0.841404</td>\n",
       "      <td>0.026021</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.003590</td>\n",
       "      <td>7.979395e-04</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.749046</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.740173</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.841025</td>\n",
       "      <td>0.794185</td>\n",
       "      <td>0.050773</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.003786</td>\n",
       "      <td>7.494325e-04</td>\n",
       "      <td>0.011570</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.849794</td>\n",
       "      <td>0.868752</td>\n",
       "      <td>0.832483</td>\n",
       "      <td>0.925272</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.880166</td>\n",
       "      <td>0.038286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.003392</td>\n",
       "      <td>4.886174e-04</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.867478</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.832483</td>\n",
       "      <td>0.868632</td>\n",
       "      <td>0.885265</td>\n",
       "      <td>0.853036</td>\n",
       "      <td>0.027030</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.003790</td>\n",
       "      <td>7.454355e-04</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.843811</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.815056</td>\n",
       "      <td>0.943699</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.867683</td>\n",
       "      <td>0.044340</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>2.033690e-03</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.812243</td>\n",
       "      <td>0.813511</td>\n",
       "      <td>0.832483</td>\n",
       "      <td>0.868632</td>\n",
       "      <td>0.823140</td>\n",
       "      <td>0.830002</td>\n",
       "      <td>0.020654</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.003187</td>\n",
       "      <td>4.007780e-04</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.804764</td>\n",
       "      <td>0.850809</td>\n",
       "      <td>0.758030</td>\n",
       "      <td>0.925272</td>\n",
       "      <td>0.943041</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.070177</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.003591</td>\n",
       "      <td>7.978324e-04</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.812243</td>\n",
       "      <td>0.804628</td>\n",
       "      <td>0.738451</td>\n",
       "      <td>0.868632</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.822149</td>\n",
       "      <td>0.052440</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.003588</td>\n",
       "      <td>7.988626e-04</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.812243</td>\n",
       "      <td>0.868752</td>\n",
       "      <td>0.850543</td>\n",
       "      <td>0.906935</td>\n",
       "      <td>0.905069</td>\n",
       "      <td>0.868708</td>\n",
       "      <td>0.035501</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.003191</td>\n",
       "      <td>3.978496e-04</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.808927</td>\n",
       "      <td>0.870047</td>\n",
       "      <td>0.796687</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.808775</td>\n",
       "      <td>0.841793</td>\n",
       "      <td>0.048679</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.004392</td>\n",
       "      <td>1.955069e-03</td>\n",
       "      <td>0.010567</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.808927</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.793565</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.844370</td>\n",
       "      <td>0.825056</td>\n",
       "      <td>0.026762</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.005390</td>\n",
       "      <td>3.372687e-03</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.869532</td>\n",
       "      <td>0.868752</td>\n",
       "      <td>0.722755</td>\n",
       "      <td>0.759244</td>\n",
       "      <td>0.847020</td>\n",
       "      <td>0.813461</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.004388</td>\n",
       "      <td>1.953722e-03</td>\n",
       "      <td>0.011570</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.822092</td>\n",
       "      <td>0.831253</td>\n",
       "      <td>0.814409</td>\n",
       "      <td>0.814409</td>\n",
       "      <td>0.823140</td>\n",
       "      <td>0.821061</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.003191</td>\n",
       "      <td>3.993516e-04</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.867478</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.758030</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.856766</td>\n",
       "      <td>0.058861</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.006579  1.198338e-03         0.014960        0.003568   \n",
       "1        0.005180  7.403577e-04         0.012567        0.001850   \n",
       "2        0.006583  1.739397e-03         0.020150        0.004568   \n",
       "3        0.005184  1.169715e-03         0.014756        0.001940   \n",
       "4        0.005780  9.757037e-04         0.016759        0.003116   \n",
       "5        0.006980  2.817703e-03         0.015163        0.001715   \n",
       "6        0.006177  7.451082e-04         0.015359        0.002570   \n",
       "7        0.003588  4.872889e-04         0.010970        0.000001   \n",
       "8        0.004389  4.892201e-04         0.010572        0.001196   \n",
       "9        0.004588  1.352374e-03         0.011768        0.003115   \n",
       "10       0.004589  7.978799e-04         0.010970        0.001093   \n",
       "11       0.004792  1.163868e-03         0.010966        0.000624   \n",
       "12       0.003990  4.623108e-07         0.010173        0.000977   \n",
       "13       0.004189  1.466311e-03         0.010771        0.000746   \n",
       "14       0.003990  6.675720e-07         0.009580        0.000493   \n",
       "15       0.003792  3.978986e-04         0.010175        0.001167   \n",
       "16       0.003986  6.316095e-04         0.010971        0.001093   \n",
       "17       0.004189  3.994945e-04         0.011968        0.001093   \n",
       "18       0.001000  6.311554e-04         0.000000        0.000000   \n",
       "19       0.000598  4.884224e-04         0.000000        0.000000   \n",
       "20       0.000798  3.992326e-04         0.000000        0.000000   \n",
       "21       0.000798  3.989941e-04         0.000000        0.000000   \n",
       "22       0.000799  3.992804e-04         0.000000        0.000000   \n",
       "23       0.000399  4.885197e-04         0.000000        0.000000   \n",
       "24       0.000804  4.018904e-04         0.000000        0.000000   \n",
       "25       0.000599  4.888904e-04         0.000000        0.000000   \n",
       "26       0.000399  4.887529e-04         0.000000        0.000000   \n",
       "27       0.000798  3.989951e-04         0.000000        0.000000   \n",
       "28       0.000799  3.996161e-04         0.000000        0.000000   \n",
       "29       0.000999  6.307007e-04         0.000000        0.000000   \n",
       "30       0.000998  1.148376e-06         0.000000        0.000000   \n",
       "31       0.000798  7.461494e-04         0.000000        0.000000   \n",
       "32       0.001199  9.763953e-04         0.000000        0.000000   \n",
       "33       0.000995  6.196315e-06         0.000000        0.000000   \n",
       "34       0.001001  1.212236e-05         0.000000        0.000000   \n",
       "35       0.001200  3.977447e-04         0.000000        0.000000   \n",
       "36       0.004189  4.004720e-04         0.011370        0.001353   \n",
       "37       0.003789  1.161413e-03         0.009571        0.000486   \n",
       "38       0.002990  4.565202e-06         0.010971        0.001544   \n",
       "39       0.003392  4.889870e-04         0.010172        0.000746   \n",
       "40       0.003192  9.772431e-04         0.010573        0.001195   \n",
       "41       0.003590  7.979395e-04         0.011170        0.000746   \n",
       "42       0.003786  7.494325e-04         0.011570        0.002793   \n",
       "43       0.003392  4.886174e-04         0.009973        0.000630   \n",
       "44       0.003790  7.454355e-04         0.010777        0.001164   \n",
       "45       0.004189  2.033690e-03         0.010374        0.000802   \n",
       "46       0.003187  4.007780e-04         0.010976        0.000631   \n",
       "47       0.003591  7.978324e-04         0.009978        0.000009   \n",
       "48       0.003588  7.988626e-04         0.012367        0.002933   \n",
       "49       0.003191  3.978496e-04         0.010373        0.001018   \n",
       "50       0.004392  1.955069e-03         0.010567        0.000795   \n",
       "51       0.005390  3.372687e-03         0.010768        0.001588   \n",
       "52       0.004388  1.953722e-03         0.011570        0.001493   \n",
       "53       0.003191  3.993516e-04         0.010973        0.001543   \n",
       "\n",
       "   param_class_weight param_criterion param_max_features param_splitter  \\\n",
       "0            balanced            gini               None           best   \n",
       "1            balanced            gini               None         random   \n",
       "2            balanced            gini               sqrt           best   \n",
       "3            balanced            gini               sqrt         random   \n",
       "4            balanced            gini               log2           best   \n",
       "5            balanced            gini               log2         random   \n",
       "6            balanced         entropy               None           best   \n",
       "7            balanced         entropy               None         random   \n",
       "8            balanced         entropy               sqrt           best   \n",
       "9            balanced         entropy               sqrt         random   \n",
       "10           balanced         entropy               log2           best   \n",
       "11           balanced         entropy               log2         random   \n",
       "12           balanced        log_loss               None           best   \n",
       "13           balanced        log_loss               None         random   \n",
       "14           balanced        log_loss               sqrt           best   \n",
       "15           balanced        log_loss               sqrt         random   \n",
       "16           balanced        log_loss               log2           best   \n",
       "17           balanced        log_loss               log2         random   \n",
       "18               dict            gini               None           best   \n",
       "19               dict            gini               None         random   \n",
       "20               dict            gini               sqrt           best   \n",
       "21               dict            gini               sqrt         random   \n",
       "22               dict            gini               log2           best   \n",
       "23               dict            gini               log2         random   \n",
       "24               dict         entropy               None           best   \n",
       "25               dict         entropy               None         random   \n",
       "26               dict         entropy               sqrt           best   \n",
       "27               dict         entropy               sqrt         random   \n",
       "28               dict         entropy               log2           best   \n",
       "29               dict         entropy               log2         random   \n",
       "30               dict        log_loss               None           best   \n",
       "31               dict        log_loss               None         random   \n",
       "32               dict        log_loss               sqrt           best   \n",
       "33               dict        log_loss               sqrt         random   \n",
       "34               dict        log_loss               log2           best   \n",
       "35               dict        log_loss               log2         random   \n",
       "36               None            gini               None           best   \n",
       "37               None            gini               None         random   \n",
       "38               None            gini               sqrt           best   \n",
       "39               None            gini               sqrt         random   \n",
       "40               None            gini               log2           best   \n",
       "41               None            gini               log2         random   \n",
       "42               None         entropy               None           best   \n",
       "43               None         entropy               None         random   \n",
       "44               None         entropy               sqrt           best   \n",
       "45               None         entropy               sqrt         random   \n",
       "46               None         entropy               log2           best   \n",
       "47               None         entropy               log2         random   \n",
       "48               None        log_loss               None           best   \n",
       "49               None        log_loss               None         random   \n",
       "50               None        log_loss               sqrt           best   \n",
       "51               None        log_loss               sqrt         random   \n",
       "52               None        log_loss               log2           best   \n",
       "53               None        log_loss               log2         random   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'class_weight': 'balanced', 'criterion': 'gin...           0.826263   \n",
       "1   {'class_weight': 'balanced', 'criterion': 'gin...           0.808927   \n",
       "2   {'class_weight': 'balanced', 'criterion': 'gin...           0.847141   \n",
       "3   {'class_weight': 'balanced', 'criterion': 'gin...           0.799620   \n",
       "4   {'class_weight': 'balanced', 'criterion': 'gin...           0.826263   \n",
       "5   {'class_weight': 'balanced', 'criterion': 'gin...           0.743022   \n",
       "6   {'class_weight': 'balanced', 'criterion': 'ent...           0.832255   \n",
       "7   {'class_weight': 'balanced', 'criterion': 'ent...           0.885356   \n",
       "8   {'class_weight': 'balanced', 'criterion': 'ent...           0.826263   \n",
       "9   {'class_weight': 'balanced', 'criterion': 'ent...           0.791752   \n",
       "10  {'class_weight': 'balanced', 'criterion': 'ent...           0.847141   \n",
       "11  {'class_weight': 'balanced', 'criterion': 'ent...           0.808927   \n",
       "12  {'class_weight': 'balanced', 'criterion': 'log...           0.829615   \n",
       "13  {'class_weight': 'balanced', 'criterion': 'log...           0.812243   \n",
       "14  {'class_weight': 'balanced', 'criterion': 'log...           0.847141   \n",
       "15  {'class_weight': 'balanced', 'criterion': 'log...           0.832255   \n",
       "16  {'class_weight': 'balanced', 'criterion': 'log...           0.826263   \n",
       "17  {'class_weight': 'balanced', 'criterion': 'log...           0.808927   \n",
       "18  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "19  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "20  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "21  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "22  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "23  {'class_weight': 'dict', 'criterion': 'gini', ...                NaN   \n",
       "24  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "25  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "26  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "27  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "28  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "29  {'class_weight': 'dict', 'criterion': 'entropy...                NaN   \n",
       "30  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "31  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "32  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "33  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "34  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "35  {'class_weight': 'dict', 'criterion': 'log_los...                NaN   \n",
       "36  {'class_weight': None, 'criterion': 'gini', 'm...           0.829615   \n",
       "37  {'class_weight': None, 'criterion': 'gini', 'm...           0.804764   \n",
       "38  {'class_weight': None, 'criterion': 'gini', 'm...           0.782557   \n",
       "39  {'class_weight': None, 'criterion': 'gini', 'm...           0.829615   \n",
       "40  {'class_weight': None, 'criterion': 'gini', 'm...           0.887346   \n",
       "41  {'class_weight': None, 'criterion': 'gini', 'm...           0.749046   \n",
       "42  {'class_weight': None, 'criterion': 'entropy',...           0.849794   \n",
       "43  {'class_weight': None, 'criterion': 'entropy',...           0.867478   \n",
       "44  {'class_weight': None, 'criterion': 'entropy',...           0.843811   \n",
       "45  {'class_weight': None, 'criterion': 'entropy',...           0.812243   \n",
       "46  {'class_weight': None, 'criterion': 'entropy',...           0.804764   \n",
       "47  {'class_weight': None, 'criterion': 'entropy',...           0.812243   \n",
       "48  {'class_weight': None, 'criterion': 'log_loss'...           0.812243   \n",
       "49  {'class_weight': None, 'criterion': 'log_loss'...           0.808927   \n",
       "50  {'class_weight': None, 'criterion': 'log_loss'...           0.808927   \n",
       "51  {'class_weight': None, 'criterion': 'log_loss'...           0.869532   \n",
       "52  {'class_weight': None, 'criterion': 'log_loss'...           0.822092   \n",
       "53  {'class_weight': None, 'criterion': 'log_loss'...           0.867478   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.868752           0.833323           0.906935   \n",
       "1            0.811321           0.775815           0.795256   \n",
       "2            0.846714           0.814409           0.832483   \n",
       "3            0.811321           0.813179           0.849057   \n",
       "4            0.870047           0.814409           0.831098   \n",
       "5            0.850809           0.740173           0.832483   \n",
       "6            0.849057           0.832483           0.870362   \n",
       "7            0.815954           0.832483           0.851527   \n",
       "8            0.831253           0.850543           0.870362   \n",
       "9            0.790949           0.793565           0.814409   \n",
       "10           0.850809           0.813179           0.813179   \n",
       "11           0.811321           0.778067           0.867097   \n",
       "12           0.868752           0.814409           0.925272   \n",
       "13           0.813511           0.831098           0.924528   \n",
       "14           0.811321           0.796687           0.886792   \n",
       "15           0.850809           0.795256           0.867097   \n",
       "16           0.831253           0.796284           0.906166   \n",
       "17           0.815037           0.759244           0.849057   \n",
       "18                NaN                NaN                NaN   \n",
       "19                NaN                NaN                NaN   \n",
       "20                NaN                NaN                NaN   \n",
       "21                NaN                NaN                NaN   \n",
       "22                NaN                NaN                NaN   \n",
       "23                NaN                NaN                NaN   \n",
       "24                NaN                NaN                NaN   \n",
       "25                NaN                NaN                NaN   \n",
       "26                NaN                NaN                NaN   \n",
       "27                NaN                NaN                NaN   \n",
       "28                NaN                NaN                NaN   \n",
       "29                NaN                NaN                NaN   \n",
       "30                NaN                NaN                NaN   \n",
       "31                NaN                NaN                NaN   \n",
       "32                NaN                NaN                NaN   \n",
       "33                NaN                NaN                NaN   \n",
       "34                NaN                NaN                NaN   \n",
       "35                NaN                NaN                NaN   \n",
       "36           0.849057           0.833323           0.870362   \n",
       "37           0.790949           0.850543           0.886792   \n",
       "38           0.813511           0.832483           0.870362   \n",
       "39           0.849057           0.740173           0.905069   \n",
       "40           0.813511           0.850543           0.832483   \n",
       "41           0.773585           0.740173           0.867097   \n",
       "42           0.868752           0.832483           0.925272   \n",
       "43           0.811321           0.832483           0.868632   \n",
       "44           0.849057           0.815056           0.943699   \n",
       "45           0.813511           0.832483           0.868632   \n",
       "46           0.850809           0.758030           0.925272   \n",
       "47           0.804628           0.738451           0.868632   \n",
       "48           0.868752           0.850543           0.906935   \n",
       "49           0.870047           0.796687           0.924528   \n",
       "50           0.811321           0.793565           0.867097   \n",
       "51           0.868752           0.722755           0.759244   \n",
       "52           0.831253           0.814409           0.814409   \n",
       "53           0.849057           0.758030           0.867097   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.924528         0.871960        0.038931                2  \n",
       "1            0.829124         0.804089        0.017776               33  \n",
       "2            0.847020         0.837553        0.012859               22  \n",
       "3            0.826499         0.819935        0.016874               29  \n",
       "4            0.883278         0.845019        0.026731               15  \n",
       "5            0.829124         0.799122        0.047554               35  \n",
       "6            0.905069         0.857845        0.027430                8  \n",
       "7            0.923510         0.861766        0.038549                6  \n",
       "8            0.841025         0.843889        0.015644               16  \n",
       "9            0.811321         0.800399        0.010260               34  \n",
       "10           0.923510         0.849564        0.040307               13  \n",
       "11           0.756031         0.804288        0.037503               32  \n",
       "12           0.905069         0.868623        0.042422                4  \n",
       "13           0.923510         0.860978        0.051904                7  \n",
       "14           0.885265         0.845441        0.036986               14  \n",
       "15           0.849057         0.838895        0.024450               21  \n",
       "16           0.791152         0.830223        0.041140               24  \n",
       "17           0.849057         0.816264        0.033037               30  \n",
       "18                NaN              NaN             NaN               37  \n",
       "19                NaN              NaN             NaN               37  \n",
       "20                NaN              NaN             NaN               37  \n",
       "21                NaN              NaN             NaN               37  \n",
       "22                NaN              NaN             NaN               37  \n",
       "23                NaN              NaN             NaN               37  \n",
       "24                NaN              NaN             NaN               37  \n",
       "25                NaN              NaN             NaN               37  \n",
       "26                NaN              NaN             NaN               37  \n",
       "27                NaN              NaN             NaN               37  \n",
       "28                NaN              NaN             NaN               37  \n",
       "29                NaN              NaN             NaN               37  \n",
       "30                NaN              NaN             NaN               37  \n",
       "31                NaN              NaN             NaN               37  \n",
       "32                NaN              NaN             NaN               37  \n",
       "33                NaN              NaN             NaN               37  \n",
       "34                NaN              NaN             NaN               37  \n",
       "35                NaN              NaN             NaN               37  \n",
       "36           0.905069         0.857485        0.027791                9  \n",
       "37           0.883278         0.843265        0.039415               17  \n",
       "38           0.883278         0.836438        0.036849               23  \n",
       "39           0.885265         0.841836        0.057309               18  \n",
       "40           0.823140         0.841404        0.026021               20  \n",
       "41           0.841025         0.794185        0.050773               36  \n",
       "42           0.924528         0.880166        0.038286                1  \n",
       "43           0.885265         0.853036        0.027030               12  \n",
       "44           0.886792         0.867683        0.044340                5  \n",
       "45           0.823140         0.830002        0.020654               25  \n",
       "46           0.943041         0.856383        0.070177               11  \n",
       "47           0.886792         0.822149        0.052440               27  \n",
       "48           0.905069         0.868708        0.035501                3  \n",
       "49           0.808775         0.841793        0.048679               19  \n",
       "50           0.844370         0.825056        0.026762               26  \n",
       "51           0.847020         0.813461        0.060818               31  \n",
       "52           0.823140         0.821061        0.006289               28  \n",
       "53           0.942166         0.856766        0.058861               10  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table= pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce041c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8801657906849198"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b9547f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3run\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6.90094695e+01,  5.91413422e+03, -2.05850391e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_input= sc.transform([[35,60000,0]])\n",
    "pre_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1904615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result= grid.predict(pre_input)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619036c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
