{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9907f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d79233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"insurance_pre.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91260e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "313ede0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent=dataset[['age', 'bmi', 'children','sex_male', 'smoker_yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e1c5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent=dataset[['charges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051ae97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 313\n",
      "[LightGBM] [Info] Number of data points in the train set: 1338, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 13270.422260\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LGBMRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200, 500, 1000]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LGBMRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200, 500, 1000]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LGBMRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 5, 7],\n",
       "                         'n_estimators': [50, 100, 200, 500, 1000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor \n",
    "param_grid={'n_estimators': [50, 100, 200,500,1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],}\n",
    "grid=GridSearchCV(LGBMRegressor(),param_grid,refit=True,verbose=3,n_jobs=-1)\n",
    "grid.fit(independent,dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee37f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402e1278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8628231946346219"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549a8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "re=grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1bdb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218698</td>\n",
       "      <td>0.069861</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.557956</td>\n",
       "      <td>0.522660</td>\n",
       "      <td>0.533052</td>\n",
       "      <td>0.545102</td>\n",
       "      <td>0.540986</td>\n",
       "      <td>0.539951</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.168710</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.765052</td>\n",
       "      <td>0.712229</td>\n",
       "      <td>0.740688</td>\n",
       "      <td>0.739026</td>\n",
       "      <td>0.742400</td>\n",
       "      <td>0.739879</td>\n",
       "      <td>0.016769</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.262439</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.869871</td>\n",
       "      <td>0.802934</td>\n",
       "      <td>0.861642</td>\n",
       "      <td>0.835705</td>\n",
       "      <td>0.847661</td>\n",
       "      <td>0.843563</td>\n",
       "      <td>0.023445</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.677651</td>\n",
       "      <td>0.026994</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.884487</td>\n",
       "      <td>0.815271</td>\n",
       "      <td>0.894805</td>\n",
       "      <td>0.852418</td>\n",
       "      <td>0.866887</td>\n",
       "      <td>0.862774</td>\n",
       "      <td>0.027850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.260504</td>\n",
       "      <td>0.034072</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.880424</td>\n",
       "      <td>0.811760</td>\n",
       "      <td>0.894254</td>\n",
       "      <td>0.852125</td>\n",
       "      <td>0.861316</td>\n",
       "      <td>0.859976</td>\n",
       "      <td>0.028218</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.134339</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.565401</td>\n",
       "      <td>0.529516</td>\n",
       "      <td>0.540273</td>\n",
       "      <td>0.548101</td>\n",
       "      <td>0.541983</td>\n",
       "      <td>0.545055</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.268686</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.768386</td>\n",
       "      <td>0.717252</td>\n",
       "      <td>0.750832</td>\n",
       "      <td>0.744604</td>\n",
       "      <td>0.742790</td>\n",
       "      <td>0.744773</td>\n",
       "      <td>0.016466</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.503007</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.867886</td>\n",
       "      <td>0.801622</td>\n",
       "      <td>0.867744</td>\n",
       "      <td>0.836866</td>\n",
       "      <td>0.847173</td>\n",
       "      <td>0.844258</td>\n",
       "      <td>0.024458</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.106069</td>\n",
       "      <td>0.060359</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.877648</td>\n",
       "      <td>0.805306</td>\n",
       "      <td>0.891038</td>\n",
       "      <td>0.846113</td>\n",
       "      <td>0.861190</td>\n",
       "      <td>0.856259</td>\n",
       "      <td>0.029633</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.947800</td>\n",
       "      <td>0.069749</td>\n",
       "      <td>0.018745</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.872175</td>\n",
       "      <td>0.798698</td>\n",
       "      <td>0.886727</td>\n",
       "      <td>0.845046</td>\n",
       "      <td>0.855301</td>\n",
       "      <td>0.851590</td>\n",
       "      <td>0.030042</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.153089</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.565129</td>\n",
       "      <td>0.529865</td>\n",
       "      <td>0.541177</td>\n",
       "      <td>0.548829</td>\n",
       "      <td>0.539830</td>\n",
       "      <td>0.544966</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.296803</td>\n",
       "      <td>0.038263</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.767262</td>\n",
       "      <td>0.715389</td>\n",
       "      <td>0.751178</td>\n",
       "      <td>0.743623</td>\n",
       "      <td>0.739423</td>\n",
       "      <td>0.743375</td>\n",
       "      <td>0.016914</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.524878</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.865692</td>\n",
       "      <td>0.797393</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.833936</td>\n",
       "      <td>0.845271</td>\n",
       "      <td>0.841858</td>\n",
       "      <td>0.025502</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.280945</td>\n",
       "      <td>0.048404</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.873831</td>\n",
       "      <td>0.799289</td>\n",
       "      <td>0.887062</td>\n",
       "      <td>0.841805</td>\n",
       "      <td>0.860015</td>\n",
       "      <td>0.852401</td>\n",
       "      <td>0.030502</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.457287</td>\n",
       "      <td>0.162822</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.866954</td>\n",
       "      <td>0.791386</td>\n",
       "      <td>0.880745</td>\n",
       "      <td>0.839387</td>\n",
       "      <td>0.852093</td>\n",
       "      <td>0.846113</td>\n",
       "      <td>0.030691</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.074982</td>\n",
       "      <td>0.018218</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.885009</td>\n",
       "      <td>0.815430</td>\n",
       "      <td>0.894452</td>\n",
       "      <td>0.852458</td>\n",
       "      <td>0.866767</td>\n",
       "      <td>0.862823</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.128095</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.881497</td>\n",
       "      <td>0.811597</td>\n",
       "      <td>0.893434</td>\n",
       "      <td>0.851057</td>\n",
       "      <td>0.860707</td>\n",
       "      <td>0.859658</td>\n",
       "      <td>0.028294</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.256188</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.875384</td>\n",
       "      <td>0.803791</td>\n",
       "      <td>0.887614</td>\n",
       "      <td>0.849924</td>\n",
       "      <td>0.855275</td>\n",
       "      <td>0.854398</td>\n",
       "      <td>0.028725</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.642146</td>\n",
       "      <td>0.123752</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.867053</td>\n",
       "      <td>0.792254</td>\n",
       "      <td>0.874023</td>\n",
       "      <td>0.842602</td>\n",
       "      <td>0.847213</td>\n",
       "      <td>0.844629</td>\n",
       "      <td>0.028708</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.371868</td>\n",
       "      <td>0.059588</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.007840</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.854633</td>\n",
       "      <td>0.780276</td>\n",
       "      <td>0.862542</td>\n",
       "      <td>0.832763</td>\n",
       "      <td>0.839521</td>\n",
       "      <td>0.833947</td>\n",
       "      <td>0.028840</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.150789</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.879432</td>\n",
       "      <td>0.805027</td>\n",
       "      <td>0.890906</td>\n",
       "      <td>0.845394</td>\n",
       "      <td>0.860792</td>\n",
       "      <td>0.856310</td>\n",
       "      <td>0.030002</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.235550</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.873535</td>\n",
       "      <td>0.798158</td>\n",
       "      <td>0.885281</td>\n",
       "      <td>0.844743</td>\n",
       "      <td>0.855125</td>\n",
       "      <td>0.851368</td>\n",
       "      <td>0.030102</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.394897</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>0.006914</td>\n",
       "      <td>0.006464</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.865641</td>\n",
       "      <td>0.788939</td>\n",
       "      <td>0.876039</td>\n",
       "      <td>0.837848</td>\n",
       "      <td>0.848433</td>\n",
       "      <td>0.843380</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.015671</td>\n",
       "      <td>0.069988</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.850018</td>\n",
       "      <td>0.771478</td>\n",
       "      <td>0.860060</td>\n",
       "      <td>0.825954</td>\n",
       "      <td>0.836173</td>\n",
       "      <td>0.828737</td>\n",
       "      <td>0.030905</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.616649</td>\n",
       "      <td>0.334036</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.834369</td>\n",
       "      <td>0.755537</td>\n",
       "      <td>0.845498</td>\n",
       "      <td>0.816592</td>\n",
       "      <td>0.822560</td>\n",
       "      <td>0.814911</td>\n",
       "      <td>0.031307</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.292228</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.005965</td>\n",
       "      <td>0.007989</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.872454</td>\n",
       "      <td>0.797340</td>\n",
       "      <td>0.886863</td>\n",
       "      <td>0.841266</td>\n",
       "      <td>0.860529</td>\n",
       "      <td>0.851690</td>\n",
       "      <td>0.031013</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.297377</td>\n",
       "      <td>0.052014</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.865716</td>\n",
       "      <td>0.788205</td>\n",
       "      <td>0.879801</td>\n",
       "      <td>0.840428</td>\n",
       "      <td>0.852010</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>0.031419</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.501280</td>\n",
       "      <td>0.036788</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.859034</td>\n",
       "      <td>0.774749</td>\n",
       "      <td>0.871830</td>\n",
       "      <td>0.830397</td>\n",
       "      <td>0.844499</td>\n",
       "      <td>0.836102</td>\n",
       "      <td>0.033674</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.129941</td>\n",
       "      <td>0.040630</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.005895</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.840693</td>\n",
       "      <td>0.756376</td>\n",
       "      <td>0.854030</td>\n",
       "      <td>0.821448</td>\n",
       "      <td>0.829899</td>\n",
       "      <td>0.820489</td>\n",
       "      <td>0.033862</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.227620</td>\n",
       "      <td>0.888929</td>\n",
       "      <td>0.036407</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.822701</td>\n",
       "      <td>0.734859</td>\n",
       "      <td>0.836130</td>\n",
       "      <td>0.811977</td>\n",
       "      <td>0.813071</td>\n",
       "      <td>0.803748</td>\n",
       "      <td>0.035519</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.172349</td>\n",
       "      <td>0.137425</td>\n",
       "      <td>0.006695</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.879834</td>\n",
       "      <td>0.810042</td>\n",
       "      <td>0.893360</td>\n",
       "      <td>0.851164</td>\n",
       "      <td>0.860489</td>\n",
       "      <td>0.858978</td>\n",
       "      <td>0.028549</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.208042</td>\n",
       "      <td>0.089276</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.874739</td>\n",
       "      <td>0.802109</td>\n",
       "      <td>0.886793</td>\n",
       "      <td>0.850442</td>\n",
       "      <td>0.854193</td>\n",
       "      <td>0.853655</td>\n",
       "      <td>0.029018</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.423664</td>\n",
       "      <td>0.093690</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.867444</td>\n",
       "      <td>0.794144</td>\n",
       "      <td>0.877491</td>\n",
       "      <td>0.843436</td>\n",
       "      <td>0.846759</td>\n",
       "      <td>0.845855</td>\n",
       "      <td>0.028801</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.873465</td>\n",
       "      <td>0.082016</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.854281</td>\n",
       "      <td>0.779449</td>\n",
       "      <td>0.858749</td>\n",
       "      <td>0.832598</td>\n",
       "      <td>0.835534</td>\n",
       "      <td>0.832122</td>\n",
       "      <td>0.028236</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.460846</td>\n",
       "      <td>0.153841</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.836669</td>\n",
       "      <td>0.764127</td>\n",
       "      <td>0.842437</td>\n",
       "      <td>0.824245</td>\n",
       "      <td>0.824599</td>\n",
       "      <td>0.818415</td>\n",
       "      <td>0.028034</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.143713</td>\n",
       "      <td>0.018218</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.871138</td>\n",
       "      <td>0.800607</td>\n",
       "      <td>0.882525</td>\n",
       "      <td>0.842429</td>\n",
       "      <td>0.855684</td>\n",
       "      <td>0.850477</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.206203</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.861635</td>\n",
       "      <td>0.791570</td>\n",
       "      <td>0.873479</td>\n",
       "      <td>0.837176</td>\n",
       "      <td>0.846477</td>\n",
       "      <td>0.842068</td>\n",
       "      <td>0.028153</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.406582</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.851974</td>\n",
       "      <td>0.777293</td>\n",
       "      <td>0.863220</td>\n",
       "      <td>0.828458</td>\n",
       "      <td>0.838123</td>\n",
       "      <td>0.831814</td>\n",
       "      <td>0.029720</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.903055</td>\n",
       "      <td>0.057994</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.832196</td>\n",
       "      <td>0.756317</td>\n",
       "      <td>0.842713</td>\n",
       "      <td>0.817329</td>\n",
       "      <td>0.821383</td>\n",
       "      <td>0.813988</td>\n",
       "      <td>0.030161</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.789814</td>\n",
       "      <td>0.096041</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.812374</td>\n",
       "      <td>0.732499</td>\n",
       "      <td>0.821122</td>\n",
       "      <td>0.806264</td>\n",
       "      <td>0.803736</td>\n",
       "      <td>0.795199</td>\n",
       "      <td>0.031917</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.118722</td>\n",
       "      <td>0.018746</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.865874</td>\n",
       "      <td>0.785103</td>\n",
       "      <td>0.878710</td>\n",
       "      <td>0.836516</td>\n",
       "      <td>0.851420</td>\n",
       "      <td>0.843525</td>\n",
       "      <td>0.032441</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.221824</td>\n",
       "      <td>0.036166</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.858419</td>\n",
       "      <td>0.772797</td>\n",
       "      <td>0.868628</td>\n",
       "      <td>0.828089</td>\n",
       "      <td>0.844034</td>\n",
       "      <td>0.834393</td>\n",
       "      <td>0.033693</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.374912</td>\n",
       "      <td>0.046340</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.846217</td>\n",
       "      <td>0.757154</td>\n",
       "      <td>0.853921</td>\n",
       "      <td>0.822631</td>\n",
       "      <td>0.830415</td>\n",
       "      <td>0.822067</td>\n",
       "      <td>0.034298</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.060891</td>\n",
       "      <td>0.058994</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.822161</td>\n",
       "      <td>0.730055</td>\n",
       "      <td>0.827725</td>\n",
       "      <td>0.809452</td>\n",
       "      <td>0.814728</td>\n",
       "      <td>0.800824</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.114589</td>\n",
       "      <td>0.324250</td>\n",
       "      <td>0.024941</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.798406</td>\n",
       "      <td>0.697593</td>\n",
       "      <td>0.806465</td>\n",
       "      <td>0.798312</td>\n",
       "      <td>0.796049</td>\n",
       "      <td>0.779365</td>\n",
       "      <td>0.041039</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.218698      0.069861         0.003127        0.006254   \n",
       "1        0.168710      0.018217         0.006249        0.007653   \n",
       "2        0.262439      0.006249         0.003124        0.006248   \n",
       "3        0.677651      0.026994         0.012497        0.006248   \n",
       "4        1.260504      0.034072         0.012496        0.006248   \n",
       "5        0.134339      0.012496         0.006249        0.007653   \n",
       "6        0.268686      0.006248         0.003124        0.006248   \n",
       "7        0.503007      0.011690         0.000000        0.000000   \n",
       "8        1.106069      0.060359         0.014906        0.001431   \n",
       "9        1.947800      0.069749         0.018745        0.006240   \n",
       "10       0.153089      0.024994         0.006249        0.007653   \n",
       "11       0.296803      0.038263         0.006249        0.007653   \n",
       "12       0.524878      0.027237         0.012500        0.006250   \n",
       "13       1.280945      0.048404         0.006249        0.007653   \n",
       "14       2.457287      0.162822         0.025069        0.007715   \n",
       "15       0.074982      0.018218         0.003125        0.006249   \n",
       "16       0.128095      0.011690         0.003124        0.006249   \n",
       "17       0.256188      0.021186         0.003124        0.006248   \n",
       "18       0.642146      0.123752         0.008971        0.007361   \n",
       "19       1.371868      0.059588         0.007715        0.007840   \n",
       "20       0.150789      0.024250         0.003862        0.006051   \n",
       "21       0.235550      0.035294         0.005518        0.005717   \n",
       "22       0.394897      0.018983         0.006914        0.006464   \n",
       "23       1.015671      0.069988         0.011884        0.003139   \n",
       "24       2.616649      0.334036         0.019932        0.011804   \n",
       "25       0.292228      0.033689         0.005965        0.007989   \n",
       "26       0.297377      0.052014         0.002221        0.002734   \n",
       "27       0.501280      0.036788         0.008907        0.003924   \n",
       "28       1.129941      0.040630         0.006739        0.005895   \n",
       "29       3.227620      0.888929         0.036407        0.017476   \n",
       "30       0.172349      0.137425         0.006695        0.001000   \n",
       "31       0.208042      0.089276         0.006386        0.001016   \n",
       "32       0.423664      0.093690         0.008178        0.001164   \n",
       "33       0.873465      0.082016         0.008975        0.001094   \n",
       "34       1.460846      0.153841         0.015624        0.000006   \n",
       "35       0.143713      0.018218         0.003125        0.006250   \n",
       "36       0.206203      0.006249         0.012498        0.006249   \n",
       "37       0.406582      0.017375         0.012497        0.006248   \n",
       "38       0.903055      0.057994         0.009373        0.007653   \n",
       "39       1.789814      0.096041         0.015626        0.000008   \n",
       "40       0.118722      0.018746         0.003124        0.006249   \n",
       "41       0.221824      0.036166         0.006248        0.007652   \n",
       "42       0.374912      0.046340         0.009373        0.007653   \n",
       "43       1.060891      0.058994         0.006252        0.007657   \n",
       "44       2.114589      0.324250         0.024941        0.007597   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                 0.01               3                 50   \n",
       "1                 0.01               3                100   \n",
       "2                 0.01               3                200   \n",
       "3                 0.01               3                500   \n",
       "4                 0.01               3               1000   \n",
       "5                 0.01               5                 50   \n",
       "6                 0.01               5                100   \n",
       "7                 0.01               5                200   \n",
       "8                 0.01               5                500   \n",
       "9                 0.01               5               1000   \n",
       "10                0.01               7                 50   \n",
       "11                0.01               7                100   \n",
       "12                0.01               7                200   \n",
       "13                0.01               7                500   \n",
       "14                0.01               7               1000   \n",
       "15                 0.1               3                 50   \n",
       "16                 0.1               3                100   \n",
       "17                 0.1               3                200   \n",
       "18                 0.1               3                500   \n",
       "19                 0.1               3               1000   \n",
       "20                 0.1               5                 50   \n",
       "21                 0.1               5                100   \n",
       "22                 0.1               5                200   \n",
       "23                 0.1               5                500   \n",
       "24                 0.1               5               1000   \n",
       "25                 0.1               7                 50   \n",
       "26                 0.1               7                100   \n",
       "27                 0.1               7                200   \n",
       "28                 0.1               7                500   \n",
       "29                 0.1               7               1000   \n",
       "30                 0.2               3                 50   \n",
       "31                 0.2               3                100   \n",
       "32                 0.2               3                200   \n",
       "33                 0.2               3                500   \n",
       "34                 0.2               3               1000   \n",
       "35                 0.2               5                 50   \n",
       "36                 0.2               5                100   \n",
       "37                 0.2               5                200   \n",
       "38                 0.2               5                500   \n",
       "39                 0.2               5               1000   \n",
       "40                 0.2               7                 50   \n",
       "41                 0.2               7                100   \n",
       "42                 0.2               7                200   \n",
       "43                 0.2               7                500   \n",
       "44                 0.2               7               1000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.557956   \n",
       "1   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.765052   \n",
       "2   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.869871   \n",
       "3   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.884487   \n",
       "4   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.880424   \n",
       "5   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.565401   \n",
       "6   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.768386   \n",
       "7   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.867886   \n",
       "8   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.877648   \n",
       "9   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.872175   \n",
       "10  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...           0.565129   \n",
       "11  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...           0.767262   \n",
       "12  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...           0.865692   \n",
       "13  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...           0.873831   \n",
       "14  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...           0.866954   \n",
       "15  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.885009   \n",
       "16  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.881497   \n",
       "17  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.875384   \n",
       "18  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.867053   \n",
       "19  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.854633   \n",
       "20  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.879432   \n",
       "21  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.873535   \n",
       "22  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.865641   \n",
       "23  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.850018   \n",
       "24  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.834369   \n",
       "25  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.872454   \n",
       "26  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.865716   \n",
       "27  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.859034   \n",
       "28  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.840693   \n",
       "29  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.822701   \n",
       "30  {'learning_rate': 0.2, 'max_depth': 3, 'n_esti...           0.879834   \n",
       "31  {'learning_rate': 0.2, 'max_depth': 3, 'n_esti...           0.874739   \n",
       "32  {'learning_rate': 0.2, 'max_depth': 3, 'n_esti...           0.867444   \n",
       "33  {'learning_rate': 0.2, 'max_depth': 3, 'n_esti...           0.854281   \n",
       "34  {'learning_rate': 0.2, 'max_depth': 3, 'n_esti...           0.836669   \n",
       "35  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.871138   \n",
       "36  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.861635   \n",
       "37  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.851974   \n",
       "38  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.832196   \n",
       "39  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.812374   \n",
       "40  {'learning_rate': 0.2, 'max_depth': 7, 'n_esti...           0.865874   \n",
       "41  {'learning_rate': 0.2, 'max_depth': 7, 'n_esti...           0.858419   \n",
       "42  {'learning_rate': 0.2, 'max_depth': 7, 'n_esti...           0.846217   \n",
       "43  {'learning_rate': 0.2, 'max_depth': 7, 'n_esti...           0.822161   \n",
       "44  {'learning_rate': 0.2, 'max_depth': 7, 'n_esti...           0.798406   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.522660           0.533052           0.545102   \n",
       "1            0.712229           0.740688           0.739026   \n",
       "2            0.802934           0.861642           0.835705   \n",
       "3            0.815271           0.894805           0.852418   \n",
       "4            0.811760           0.894254           0.852125   \n",
       "5            0.529516           0.540273           0.548101   \n",
       "6            0.717252           0.750832           0.744604   \n",
       "7            0.801622           0.867744           0.836866   \n",
       "8            0.805306           0.891038           0.846113   \n",
       "9            0.798698           0.886727           0.845046   \n",
       "10           0.529865           0.541177           0.548829   \n",
       "11           0.715389           0.751178           0.743623   \n",
       "12           0.797393           0.867000           0.833936   \n",
       "13           0.799289           0.887062           0.841805   \n",
       "14           0.791386           0.880745           0.839387   \n",
       "15           0.815430           0.894452           0.852458   \n",
       "16           0.811597           0.893434           0.851057   \n",
       "17           0.803791           0.887614           0.849924   \n",
       "18           0.792254           0.874023           0.842602   \n",
       "19           0.780276           0.862542           0.832763   \n",
       "20           0.805027           0.890906           0.845394   \n",
       "21           0.798158           0.885281           0.844743   \n",
       "22           0.788939           0.876039           0.837848   \n",
       "23           0.771478           0.860060           0.825954   \n",
       "24           0.755537           0.845498           0.816592   \n",
       "25           0.797340           0.886863           0.841266   \n",
       "26           0.788205           0.879801           0.840428   \n",
       "27           0.774749           0.871830           0.830397   \n",
       "28           0.756376           0.854030           0.821448   \n",
       "29           0.734859           0.836130           0.811977   \n",
       "30           0.810042           0.893360           0.851164   \n",
       "31           0.802109           0.886793           0.850442   \n",
       "32           0.794144           0.877491           0.843436   \n",
       "33           0.779449           0.858749           0.832598   \n",
       "34           0.764127           0.842437           0.824245   \n",
       "35           0.800607           0.882525           0.842429   \n",
       "36           0.791570           0.873479           0.837176   \n",
       "37           0.777293           0.863220           0.828458   \n",
       "38           0.756317           0.842713           0.817329   \n",
       "39           0.732499           0.821122           0.806264   \n",
       "40           0.785103           0.878710           0.836516   \n",
       "41           0.772797           0.868628           0.828089   \n",
       "42           0.757154           0.853921           0.822631   \n",
       "43           0.730055           0.827725           0.809452   \n",
       "44           0.697593           0.806465           0.798312   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.540986         0.539951        0.011818               45  \n",
       "1            0.742400         0.739879        0.016769               42  \n",
       "2            0.847661         0.843563        0.023445               20  \n",
       "3            0.866887         0.862774        0.027850                2  \n",
       "4            0.861316         0.859976        0.028218                3  \n",
       "5            0.541983         0.545055        0.011807               43  \n",
       "6            0.742790         0.744773        0.016466               40  \n",
       "7            0.847173         0.844258        0.024458               19  \n",
       "8            0.861190         0.856259        0.029633                7  \n",
       "9            0.855301         0.851590        0.030042               12  \n",
       "10           0.539830         0.544966        0.011749               44  \n",
       "11           0.739423         0.743375        0.016914               41  \n",
       "12           0.845271         0.841858        0.025502               24  \n",
       "13           0.860015         0.852401        0.030502               10  \n",
       "14           0.852093         0.846113        0.030691               15  \n",
       "15           0.866767         0.862823        0.027791                1  \n",
       "16           0.860707         0.859658        0.028294                4  \n",
       "17           0.855275         0.854398        0.028725                8  \n",
       "18           0.847213         0.844629        0.028708               18  \n",
       "19           0.839521         0.833947        0.028840               27  \n",
       "20           0.860792         0.856310        0.030002                6  \n",
       "21           0.855125         0.851368        0.030102               13  \n",
       "22           0.848433         0.843380        0.030273               22  \n",
       "23           0.836173         0.828737        0.030905               30  \n",
       "24           0.822560         0.814911        0.031307               34  \n",
       "25           0.860529         0.851690        0.031013               11  \n",
       "26           0.852010         0.845232        0.031419               17  \n",
       "27           0.844499         0.836102        0.033674               25  \n",
       "28           0.829899         0.820489        0.033862               32  \n",
       "29           0.813071         0.803748        0.035519               36  \n",
       "30           0.860489         0.858978        0.028549                5  \n",
       "31           0.854193         0.853655        0.029018                9  \n",
       "32           0.846759         0.845855        0.028801               16  \n",
       "33           0.835534         0.832122        0.028236               28  \n",
       "34           0.824599         0.818415        0.028034               33  \n",
       "35           0.855684         0.850477        0.028400               14  \n",
       "36           0.846477         0.842068        0.028153               23  \n",
       "37           0.838123         0.831814        0.029720               29  \n",
       "38           0.821383         0.813988        0.030161               35  \n",
       "39           0.803736         0.795199        0.031917               38  \n",
       "40           0.851420         0.843525        0.032441               21  \n",
       "41           0.844034         0.834393        0.033693               26  \n",
       "42           0.830415         0.822067        0.034298               31  \n",
       "43           0.814728         0.800824        0.035931               37  \n",
       "44           0.796049         0.779365        0.041039               39  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec119a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "result= grid.predict([[32,43,2,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee06df5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43521.24399117])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb559209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
