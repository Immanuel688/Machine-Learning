{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac68eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7417809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ec846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"insurance_pre.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a724b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01712bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent=dataset[['age', 'bmi', 'children','sex_male', 'smoker_yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "871151a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent=dataset[['charges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f778cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_bi...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200, 500, 1000]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_bi...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200, 500, 1000]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_bi...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 5, 7],\n",
       "                         'n_estimators': [50, 100, 200, 500, 1000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "param_grid={'n_estimators': [50, 100, 200,500,1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],}\n",
    "grid=GridSearchCV(XGBRegressor(),param_grid,refit=True,verbose=3,n_jobs=-1)\n",
    "grid.fit(independent,dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edbe70de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56e1b124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8624627886181873"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "580a5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "re=grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a6773f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053113</td>\n",
       "      <td>0.015926</td>\n",
       "      <td>0.016065</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.551672</td>\n",
       "      <td>0.518092</td>\n",
       "      <td>0.529814</td>\n",
       "      <td>0.540705</td>\n",
       "      <td>0.539840</td>\n",
       "      <td>0.536025</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069538</td>\n",
       "      <td>0.016271</td>\n",
       "      <td>0.017983</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.760272</td>\n",
       "      <td>0.708444</td>\n",
       "      <td>0.738133</td>\n",
       "      <td>0.736334</td>\n",
       "      <td>0.744497</td>\n",
       "      <td>0.737536</td>\n",
       "      <td>0.016814</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.097673</td>\n",
       "      <td>0.016647</td>\n",
       "      <td>0.007844</td>\n",
       "      <td>0.006987</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.867756</td>\n",
       "      <td>0.801285</td>\n",
       "      <td>0.860665</td>\n",
       "      <td>0.834497</td>\n",
       "      <td>0.850608</td>\n",
       "      <td>0.842962</td>\n",
       "      <td>0.023644</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.317220</td>\n",
       "      <td>0.024417</td>\n",
       "      <td>0.004919</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.883153</td>\n",
       "      <td>0.813506</td>\n",
       "      <td>0.892568</td>\n",
       "      <td>0.852772</td>\n",
       "      <td>0.870315</td>\n",
       "      <td>0.862463</td>\n",
       "      <td>0.027881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.595042</td>\n",
       "      <td>0.039368</td>\n",
       "      <td>0.028543</td>\n",
       "      <td>0.022743</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.878784</td>\n",
       "      <td>0.811171</td>\n",
       "      <td>0.891580</td>\n",
       "      <td>0.849536</td>\n",
       "      <td>0.863596</td>\n",
       "      <td>0.858933</td>\n",
       "      <td>0.027753</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.049877</td>\n",
       "      <td>0.024940</td>\n",
       "      <td>0.034367</td>\n",
       "      <td>0.022958</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.552009</td>\n",
       "      <td>0.520179</td>\n",
       "      <td>0.531872</td>\n",
       "      <td>0.540813</td>\n",
       "      <td>0.540244</td>\n",
       "      <td>0.537023</td>\n",
       "      <td>0.010579</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100445</td>\n",
       "      <td>0.016232</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.758440</td>\n",
       "      <td>0.709164</td>\n",
       "      <td>0.742269</td>\n",
       "      <td>0.735720</td>\n",
       "      <td>0.743768</td>\n",
       "      <td>0.737872</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.197489</td>\n",
       "      <td>0.012439</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.862404</td>\n",
       "      <td>0.796348</td>\n",
       "      <td>0.863930</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.850785</td>\n",
       "      <td>0.841065</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.618118</td>\n",
       "      <td>0.049495</td>\n",
       "      <td>0.043112</td>\n",
       "      <td>0.028875</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.869352</td>\n",
       "      <td>0.802249</td>\n",
       "      <td>0.889835</td>\n",
       "      <td>0.843764</td>\n",
       "      <td>0.863538</td>\n",
       "      <td>0.853748</td>\n",
       "      <td>0.029643</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.282930</td>\n",
       "      <td>0.098057</td>\n",
       "      <td>0.034907</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.862368</td>\n",
       "      <td>0.795284</td>\n",
       "      <td>0.882868</td>\n",
       "      <td>0.839468</td>\n",
       "      <td>0.853793</td>\n",
       "      <td>0.846756</td>\n",
       "      <td>0.029325</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.546052</td>\n",
       "      <td>0.521982</td>\n",
       "      <td>0.527914</td>\n",
       "      <td>0.540246</td>\n",
       "      <td>0.536615</td>\n",
       "      <td>0.534562</td>\n",
       "      <td>0.008614</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.239359</td>\n",
       "      <td>0.014005</td>\n",
       "      <td>0.013764</td>\n",
       "      <td>0.013071</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.748675</td>\n",
       "      <td>0.707782</td>\n",
       "      <td>0.732395</td>\n",
       "      <td>0.731741</td>\n",
       "      <td>0.736825</td>\n",
       "      <td>0.731484</td>\n",
       "      <td>0.013317</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.487497</td>\n",
       "      <td>0.031178</td>\n",
       "      <td>0.015757</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.849663</td>\n",
       "      <td>0.795428</td>\n",
       "      <td>0.847499</td>\n",
       "      <td>0.820319</td>\n",
       "      <td>0.837054</td>\n",
       "      <td>0.829993</td>\n",
       "      <td>0.020157</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.291755</td>\n",
       "      <td>0.034678</td>\n",
       "      <td>0.039227</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.851522</td>\n",
       "      <td>0.794488</td>\n",
       "      <td>0.868271</td>\n",
       "      <td>0.829846</td>\n",
       "      <td>0.848582</td>\n",
       "      <td>0.838542</td>\n",
       "      <td>0.025177</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.278041</td>\n",
       "      <td>0.154520</td>\n",
       "      <td>0.028117</td>\n",
       "      <td>0.018218</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.841840</td>\n",
       "      <td>0.780934</td>\n",
       "      <td>0.857864</td>\n",
       "      <td>0.818131</td>\n",
       "      <td>0.839854</td>\n",
       "      <td>0.827725</td>\n",
       "      <td>0.026594</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.043734</td>\n",
       "      <td>0.028637</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.018218</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.882706</td>\n",
       "      <td>0.813817</td>\n",
       "      <td>0.892385</td>\n",
       "      <td>0.853029</td>\n",
       "      <td>0.869898</td>\n",
       "      <td>0.862367</td>\n",
       "      <td>0.027625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.074981</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.018218</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.877827</td>\n",
       "      <td>0.810826</td>\n",
       "      <td>0.891714</td>\n",
       "      <td>0.848998</td>\n",
       "      <td>0.862317</td>\n",
       "      <td>0.858337</td>\n",
       "      <td>0.027764</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.118719</td>\n",
       "      <td>0.021194</td>\n",
       "      <td>0.028118</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.870405</td>\n",
       "      <td>0.803895</td>\n",
       "      <td>0.884057</td>\n",
       "      <td>0.844304</td>\n",
       "      <td>0.854397</td>\n",
       "      <td>0.851411</td>\n",
       "      <td>0.027363</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.321800</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.024201</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.852336</td>\n",
       "      <td>0.779411</td>\n",
       "      <td>0.860458</td>\n",
       "      <td>0.836460</td>\n",
       "      <td>0.837460</td>\n",
       "      <td>0.833225</td>\n",
       "      <td>0.028394</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.646722</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.017113</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.837974</td>\n",
       "      <td>0.755470</td>\n",
       "      <td>0.837386</td>\n",
       "      <td>0.821534</td>\n",
       "      <td>0.807543</td>\n",
       "      <td>0.811981</td>\n",
       "      <td>0.030415</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.074986</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.018743</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.871417</td>\n",
       "      <td>0.802986</td>\n",
       "      <td>0.889836</td>\n",
       "      <td>0.843672</td>\n",
       "      <td>0.864221</td>\n",
       "      <td>0.854427</td>\n",
       "      <td>0.029666</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.103102</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.011689</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.864447</td>\n",
       "      <td>0.794779</td>\n",
       "      <td>0.882467</td>\n",
       "      <td>0.833990</td>\n",
       "      <td>0.855876</td>\n",
       "      <td>0.846312</td>\n",
       "      <td>0.030117</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.193705</td>\n",
       "      <td>0.028973</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.850868</td>\n",
       "      <td>0.770788</td>\n",
       "      <td>0.865064</td>\n",
       "      <td>0.821724</td>\n",
       "      <td>0.844176</td>\n",
       "      <td>0.830524</td>\n",
       "      <td>0.032982</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.556115</td>\n",
       "      <td>0.027238</td>\n",
       "      <td>0.037492</td>\n",
       "      <td>0.018746</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.825598</td>\n",
       "      <td>0.739251</td>\n",
       "      <td>0.832749</td>\n",
       "      <td>0.806128</td>\n",
       "      <td>0.826902</td>\n",
       "      <td>0.806126</td>\n",
       "      <td>0.034617</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.124736</td>\n",
       "      <td>0.047382</td>\n",
       "      <td>0.034367</td>\n",
       "      <td>0.022959</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.809140</td>\n",
       "      <td>0.723207</td>\n",
       "      <td>0.816084</td>\n",
       "      <td>0.799360</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.792406</td>\n",
       "      <td>0.035083</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.140592</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.850612</td>\n",
       "      <td>0.792116</td>\n",
       "      <td>0.868604</td>\n",
       "      <td>0.829207</td>\n",
       "      <td>0.847933</td>\n",
       "      <td>0.837694</td>\n",
       "      <td>0.025987</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.240569</td>\n",
       "      <td>0.025382</td>\n",
       "      <td>0.028118</td>\n",
       "      <td>0.022958</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.838871</td>\n",
       "      <td>0.778532</td>\n",
       "      <td>0.855527</td>\n",
       "      <td>0.816955</td>\n",
       "      <td>0.839685</td>\n",
       "      <td>0.825914</td>\n",
       "      <td>0.026683</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.421777</td>\n",
       "      <td>0.013973</td>\n",
       "      <td>0.028120</td>\n",
       "      <td>0.022959</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.821558</td>\n",
       "      <td>0.756666</td>\n",
       "      <td>0.835242</td>\n",
       "      <td>0.805977</td>\n",
       "      <td>0.828850</td>\n",
       "      <td>0.809658</td>\n",
       "      <td>0.028235</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.074745</td>\n",
       "      <td>0.033356</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.743155</td>\n",
       "      <td>0.820994</td>\n",
       "      <td>0.800957</td>\n",
       "      <td>0.817881</td>\n",
       "      <td>0.799316</td>\n",
       "      <td>0.028897</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.083889</td>\n",
       "      <td>0.046969</td>\n",
       "      <td>0.024992</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.812710</td>\n",
       "      <td>0.741005</td>\n",
       "      <td>0.817788</td>\n",
       "      <td>0.800121</td>\n",
       "      <td>0.816926</td>\n",
       "      <td>0.797710</td>\n",
       "      <td>0.029047</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.876863</td>\n",
       "      <td>0.810272</td>\n",
       "      <td>0.891669</td>\n",
       "      <td>0.849653</td>\n",
       "      <td>0.860610</td>\n",
       "      <td>0.857814</td>\n",
       "      <td>0.027726</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.099977</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.867868</td>\n",
       "      <td>0.800057</td>\n",
       "      <td>0.883093</td>\n",
       "      <td>0.847861</td>\n",
       "      <td>0.853364</td>\n",
       "      <td>0.850449</td>\n",
       "      <td>0.028013</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.134344</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.857255</td>\n",
       "      <td>0.784451</td>\n",
       "      <td>0.868770</td>\n",
       "      <td>0.835168</td>\n",
       "      <td>0.838090</td>\n",
       "      <td>0.836747</td>\n",
       "      <td>0.028932</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.349915</td>\n",
       "      <td>0.025383</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.836149</td>\n",
       "      <td>0.759832</td>\n",
       "      <td>0.832642</td>\n",
       "      <td>0.822073</td>\n",
       "      <td>0.808452</td>\n",
       "      <td>0.811830</td>\n",
       "      <td>0.027730</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.462395</td>\n",
       "      <td>0.041445</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.724012</td>\n",
       "      <td>0.804596</td>\n",
       "      <td>0.811125</td>\n",
       "      <td>0.789446</td>\n",
       "      <td>0.789011</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.065609</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.862461</td>\n",
       "      <td>0.793482</td>\n",
       "      <td>0.878756</td>\n",
       "      <td>0.832805</td>\n",
       "      <td>0.852166</td>\n",
       "      <td>0.843934</td>\n",
       "      <td>0.029301</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.096849</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.849009</td>\n",
       "      <td>0.770143</td>\n",
       "      <td>0.859542</td>\n",
       "      <td>0.821411</td>\n",
       "      <td>0.840592</td>\n",
       "      <td>0.828139</td>\n",
       "      <td>0.031577</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.181208</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.820508</td>\n",
       "      <td>0.747149</td>\n",
       "      <td>0.838267</td>\n",
       "      <td>0.807751</td>\n",
       "      <td>0.826128</td>\n",
       "      <td>0.807961</td>\n",
       "      <td>0.031950</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.406155</td>\n",
       "      <td>0.040736</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.799044</td>\n",
       "      <td>0.724292</td>\n",
       "      <td>0.814665</td>\n",
       "      <td>0.798286</td>\n",
       "      <td>0.811536</td>\n",
       "      <td>0.789565</td>\n",
       "      <td>0.033284</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.802936</td>\n",
       "      <td>0.037750</td>\n",
       "      <td>0.021871</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.793833</td>\n",
       "      <td>0.718596</td>\n",
       "      <td>0.809282</td>\n",
       "      <td>0.796574</td>\n",
       "      <td>0.808756</td>\n",
       "      <td>0.785408</td>\n",
       "      <td>0.033984</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.081229</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>0.024995</td>\n",
       "      <td>0.015931</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.843757</td>\n",
       "      <td>0.772489</td>\n",
       "      <td>0.842147</td>\n",
       "      <td>0.818822</td>\n",
       "      <td>0.842224</td>\n",
       "      <td>0.823888</td>\n",
       "      <td>0.027320</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.178083</td>\n",
       "      <td>0.023379</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.829836</td>\n",
       "      <td>0.754265</td>\n",
       "      <td>0.822334</td>\n",
       "      <td>0.812771</td>\n",
       "      <td>0.832366</td>\n",
       "      <td>0.810314</td>\n",
       "      <td>0.028843</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.324921</td>\n",
       "      <td>0.018219</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>0.740625</td>\n",
       "      <td>0.813484</td>\n",
       "      <td>0.807347</td>\n",
       "      <td>0.826631</td>\n",
       "      <td>0.801635</td>\n",
       "      <td>0.031179</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.727780</td>\n",
       "      <td>0.044070</td>\n",
       "      <td>0.015618</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.817657</td>\n",
       "      <td>0.737994</td>\n",
       "      <td>0.808950</td>\n",
       "      <td>0.806017</td>\n",
       "      <td>0.824526</td>\n",
       "      <td>0.799029</td>\n",
       "      <td>0.031208</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.259001</td>\n",
       "      <td>0.059615</td>\n",
       "      <td>0.021862</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.737955</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>0.805994</td>\n",
       "      <td>0.824469</td>\n",
       "      <td>0.798981</td>\n",
       "      <td>0.031203</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.053113      0.015926         0.016065        0.017930   \n",
       "1        0.069538      0.016271         0.017983        0.017600   \n",
       "2        0.097673      0.016647         0.007844        0.006987   \n",
       "3        0.317220      0.024417         0.004919        0.006381   \n",
       "4        0.595042      0.039368         0.028543        0.022743   \n",
       "5        0.049877      0.024940         0.034367        0.022958   \n",
       "6        0.100445      0.016232         0.006249        0.007653   \n",
       "7        0.197489      0.012439         0.006550        0.007427   \n",
       "8        0.618118      0.049495         0.043112        0.028875   \n",
       "9        1.282930      0.098057         0.034907        0.010778   \n",
       "10       0.127660      0.005570         0.007179        0.000747   \n",
       "11       0.239359      0.014005         0.013764        0.013071   \n",
       "12       0.487497      0.031178         0.015757        0.013576   \n",
       "13       1.291755      0.034678         0.039227        0.017956   \n",
       "14       2.278041      0.154520         0.028117        0.018218   \n",
       "15       0.043734      0.028637         0.012498        0.018218   \n",
       "16       0.074981      0.006249         0.012498        0.018218   \n",
       "17       0.118719      0.021194         0.028118        0.018217   \n",
       "18       0.321800      0.027237         0.015622        0.024201   \n",
       "19       0.646722      0.012498         0.015622        0.017113   \n",
       "20       0.074986      0.006246         0.018743        0.015306   \n",
       "21       0.103102      0.021190         0.012497        0.011689   \n",
       "22       0.193705      0.028973         0.021870        0.021189   \n",
       "23       0.556115      0.027238         0.037492        0.018746   \n",
       "24       1.124736      0.047382         0.034367        0.022959   \n",
       "25       0.140592      0.019759         0.006249        0.007654   \n",
       "26       0.240569      0.025382         0.028118        0.022958   \n",
       "27       0.421777      0.013973         0.028120        0.022959   \n",
       "28       1.074745      0.033356         0.015621        0.000001   \n",
       "29       2.083889      0.046969         0.024992        0.012499   \n",
       "30       0.043740      0.015306         0.012497        0.018217   \n",
       "31       0.099977      0.021190         0.006248        0.007653   \n",
       "32       0.134344      0.021190         0.012498        0.006249   \n",
       "33       0.349915      0.025383         0.006248        0.007653   \n",
       "34       0.462395      0.041445         0.006249        0.007654   \n",
       "35       0.065609      0.006249         0.009373        0.007653   \n",
       "36       0.096849      0.011691         0.012497        0.011690   \n",
       "37       0.181208      0.018744         0.012497        0.006248   \n",
       "38       0.406155      0.040736         0.012498        0.011690   \n",
       "39       0.802936      0.037750         0.021871        0.015932   \n",
       "40       0.081229      0.011691         0.024995        0.015931   \n",
       "41       0.178083      0.023379         0.009373        0.007653   \n",
       "42       0.324921      0.018219         0.012497        0.006249   \n",
       "43       0.727780      0.044070         0.015618        0.000002   \n",
       "44       1.259001      0.059615         0.021862        0.007644   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                 0.01               3                 50   \n",
       "1                 0.01               3                100   \n",
       "2                 0.01               3                200   \n",
       "3                 0.01               3                500   \n",
       "4                 0.01               3               1000   \n",
       "5                 0.01               5                 50   \n",
       "6                 0.01               5                100   \n",
       "7                 0.01               5                200   \n",
       "8                 0.01               5                500   \n",
       "9                 0.01               5               1000   \n",
       "10                0.01               7                 50   \n",
       "11                0.01               7                100   \n",
       "12                0.01               7                200   \n",
       "13                0.01               7                500   \n",
       "14                0.01               7               1000   \n",
       "15                 0.1               3                 50   \n",
       "16                 0.1               3                100   \n",
       "17                 0.1               3                200   \n",
       "18                 0.1               3                500   \n",
       "19                 0.1               3               1000   \n",
       "20                 0.1               5                 50   \n",
       "21                 0.1               5                100   \n",
       "22                 0.1               5                200   \n",
       "23                 0.1               5                500   \n",
       "24                 0.1               5               1000   \n",
       "25                 0.1               7                 50   \n",
       "26                 0.1               7                100   \n",
       "27                 0.1               7                200   \n",
       "28                 0.1               7                500   \n",
       "29                 0.1               7               1000   \n",
       "30                 0.2               3                 50   \n",
       "31                 0.2               3                100   \n",
       "32                 0.2               3                200   \n",
       "33                 0.2               3                500   \n",
       "34                 0.2               3               1000   \n",
       "35                 0.2               5                 50   \n",
       "36                 0.2               5                100   \n",
       "37                 0.2               5                200   \n",
       "38                 0.2               5                500   \n",
       "39                 0.2               5               1000   \n",
       "40                 0.2               7                 50   \n",
       "41                 0.2               7                100   \n",
       "42                 0.2               7                200   \n",
       "43                 0.2               7                500   \n",
       "44                 0.2               7               1000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.551672   \n",
       "1   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.760272   \n",
       "2   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.867756   \n",
       "3   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.883153   \n",
       "4   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.878784   \n",
       "5   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.552009   \n",
       "6   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.758440   \n",
       "7   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.862404   \n",
       "8   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.869352   \n",
       "9   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.862368   \n",
       "10  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...           0.546052   \n",
       "11  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...           0.748675   \n",
       "12  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...           0.849663   \n",
       "13  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...           0.851522   \n",
       "14  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...           0.841840   \n",
       "15  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.882706   \n",
       "16  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.877827   \n",
       "17  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.870405   \n",
       "18  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.852336   \n",
       "19  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.837974   \n",
       "20  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.871417   \n",
       "21  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.864447   \n",
       "22  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.850868   \n",
       "23  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.825598   \n",
       "24  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.809140   \n",
       "25  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.850612   \n",
       "26  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.838871   \n",
       "27  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.821558   \n",
       "28  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.813594   \n",
       "29  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.812710   \n",
       "30  {'learning_rate': 0.2, 'max_depth': 3, 'n_esti...           0.876863   \n",
       "31  {'learning_rate': 0.2, 'max_depth': 3, 'n_esti...           0.867868   \n",
       "32  {'learning_rate': 0.2, 'max_depth': 3, 'n_esti...           0.857255   \n",
       "33  {'learning_rate': 0.2, 'max_depth': 3, 'n_esti...           0.836149   \n",
       "34  {'learning_rate': 0.2, 'max_depth': 3, 'n_esti...           0.815873   \n",
       "35  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.862461   \n",
       "36  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.849009   \n",
       "37  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.820508   \n",
       "38  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.799044   \n",
       "39  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...           0.793833   \n",
       "40  {'learning_rate': 0.2, 'max_depth': 7, 'n_esti...           0.843757   \n",
       "41  {'learning_rate': 0.2, 'max_depth': 7, 'n_esti...           0.829836   \n",
       "42  {'learning_rate': 0.2, 'max_depth': 7, 'n_esti...           0.820088   \n",
       "43  {'learning_rate': 0.2, 'max_depth': 7, 'n_esti...           0.817657   \n",
       "44  {'learning_rate': 0.2, 'max_depth': 7, 'n_esti...           0.817620   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.518092           0.529814           0.540705   \n",
       "1            0.708444           0.738133           0.736334   \n",
       "2            0.801285           0.860665           0.834497   \n",
       "3            0.813506           0.892568           0.852772   \n",
       "4            0.811171           0.891580           0.849536   \n",
       "5            0.520179           0.531872           0.540813   \n",
       "6            0.709164           0.742269           0.735720   \n",
       "7            0.796348           0.863930           0.831858   \n",
       "8            0.802249           0.889835           0.843764   \n",
       "9            0.795284           0.882868           0.839468   \n",
       "10           0.521982           0.527914           0.540246   \n",
       "11           0.707782           0.732395           0.731741   \n",
       "12           0.795428           0.847499           0.820319   \n",
       "13           0.794488           0.868271           0.829846   \n",
       "14           0.780934           0.857864           0.818131   \n",
       "15           0.813817           0.892385           0.853029   \n",
       "16           0.810826           0.891714           0.848998   \n",
       "17           0.803895           0.884057           0.844304   \n",
       "18           0.779411           0.860458           0.836460   \n",
       "19           0.755470           0.837386           0.821534   \n",
       "20           0.802986           0.889836           0.843672   \n",
       "21           0.794779           0.882467           0.833990   \n",
       "22           0.770788           0.865064           0.821724   \n",
       "23           0.739251           0.832749           0.806128   \n",
       "24           0.723207           0.816084           0.799360   \n",
       "25           0.792116           0.868604           0.829207   \n",
       "26           0.778532           0.855527           0.816955   \n",
       "27           0.756666           0.835242           0.805977   \n",
       "28           0.743155           0.820994           0.800957   \n",
       "29           0.741005           0.817788           0.800121   \n",
       "30           0.810272           0.891669           0.849653   \n",
       "31           0.800057           0.883093           0.847861   \n",
       "32           0.784451           0.868770           0.835168   \n",
       "33           0.759832           0.832642           0.822073   \n",
       "34           0.724012           0.804596           0.811125   \n",
       "35           0.793482           0.878756           0.832805   \n",
       "36           0.770143           0.859542           0.821411   \n",
       "37           0.747149           0.838267           0.807751   \n",
       "38           0.724292           0.814665           0.798286   \n",
       "39           0.718596           0.809282           0.796574   \n",
       "40           0.772489           0.842147           0.818822   \n",
       "41           0.754265           0.822334           0.812771   \n",
       "42           0.740625           0.813484           0.807347   \n",
       "43           0.737994           0.808950           0.806017   \n",
       "44           0.737955           0.808864           0.805994   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.539840         0.536025        0.011327               44  \n",
       "1            0.744497         0.737536        0.016814               41  \n",
       "2            0.850608         0.842962        0.023644               13  \n",
       "3            0.870315         0.862463        0.027881                1  \n",
       "4            0.863596         0.858933        0.027753                3  \n",
       "5            0.540244         0.537023        0.010579               43  \n",
       "6            0.743768         0.737872        0.016161               40  \n",
       "7            0.850785         0.841065        0.025127               14  \n",
       "8            0.863538         0.853748        0.029643                7  \n",
       "9            0.853793         0.846756        0.029325               10  \n",
       "10           0.536615         0.534562        0.008614               45  \n",
       "11           0.736825         0.731484        0.013317               42  \n",
       "12           0.837054         0.829993        0.020157               20  \n",
       "13           0.848582         0.838542        0.025177               15  \n",
       "14           0.839854         0.827725        0.026594               22  \n",
       "15           0.869898         0.862367        0.027625                2  \n",
       "16           0.862317         0.858337        0.027764                4  \n",
       "17           0.854397         0.851411        0.027363                8  \n",
       "18           0.837460         0.833225        0.028394               18  \n",
       "19           0.807543         0.811981        0.030415               25  \n",
       "20           0.864221         0.854427        0.029666                6  \n",
       "21           0.855876         0.846312        0.030117               11  \n",
       "22           0.844176         0.830524        0.032982               19  \n",
       "23           0.826902         0.806126        0.034617               30  \n",
       "24           0.814237         0.792406        0.035083               36  \n",
       "25           0.847933         0.837694        0.025987               16  \n",
       "26           0.839685         0.825914        0.026683               23  \n",
       "27           0.828850         0.809658        0.028235               28  \n",
       "28           0.817881         0.799316        0.028897               32  \n",
       "29           0.816926         0.797710        0.029047               35  \n",
       "30           0.860610         0.857814        0.027726                5  \n",
       "31           0.853364         0.850449        0.028013                9  \n",
       "32           0.838090         0.836747        0.028932               17  \n",
       "33           0.808452         0.811830        0.027730               26  \n",
       "34           0.789446         0.789011        0.033700               38  \n",
       "35           0.852166         0.843934        0.029301               12  \n",
       "36           0.840592         0.828139        0.031577               21  \n",
       "37           0.826128         0.807961        0.031950               29  \n",
       "38           0.811536         0.789565        0.033284               37  \n",
       "39           0.808756         0.785408        0.033984               39  \n",
       "40           0.842224         0.823888        0.027320               24  \n",
       "41           0.832366         0.810314        0.028843               27  \n",
       "42           0.826631         0.801635        0.031179               31  \n",
       "43           0.824526         0.799029        0.031208               33  \n",
       "44           0.824469         0.798981        0.031203               34  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a687a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result= grid.predict([[32,43,2,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64de05df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42237.24], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
